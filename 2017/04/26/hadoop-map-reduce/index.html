<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="hadoop,MapReduce," />





  <link rel="alternate" href="/atom.xml" title="Ilivoo`s blog" type="application/atom+xml" />






<meta name="description" content="概述 MapReduce是一个简单的计算处理框架, 它能够在一个廉价的大型集群上以一种容错的方式并行的处理TB级的数据。 一个MapRecude任务通常讲输入数据集进行分块, 并且以完全并行的方式处理map任务, 框架对map任务输出进行。排序, 并作为reduce任务的输入, 通常任务的输入和输出都存储在文件系统, 框架负责处理协调、监控并重运行失败的任务。  通常情况下计算节点和存储节点都是在">
<meta name="keywords" content="hadoop,MapReduce">
<meta property="og:type" content="article">
<meta property="og:title" content="MapReduce使用">
<meta property="og:url" content="http://yoursite.com/2017/04/26/hadoop-map-reduce/index.html">
<meta property="og:site_name" content="Ilivoo`s blog">
<meta property="og:description" content="概述 MapReduce是一个简单的计算处理框架, 它能够在一个廉价的大型集群上以一种容错的方式并行的处理TB级的数据。 一个MapRecude任务通常讲输入数据集进行分块, 并且以完全并行的方式处理map任务, 框架对map任务输出进行。排序, 并作为reduce任务的输入, 通常任务的输入和输出都存储在文件系统, 框架负责处理协调、监控并重运行失败的任务。  通常情况下计算节点和存储节点都是在">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-12-18T07:39:35.605Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MapReduce使用">
<meta name="twitter:description" content="概述 MapReduce是一个简单的计算处理框架, 它能够在一个廉价的大型集群上以一种容错的方式并行的处理TB级的数据。 一个MapRecude任务通常讲输入数据集进行分块, 并且以完全并行的方式处理map任务, 框架对map任务输出进行。排序, 并作为reduce任务的输入, 通常任务的输入和输出都存储在文件系统, 框架负责处理协调、监控并重运行失败的任务。  通常情况下计算节点和存储节点都是在">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/04/26/hadoop-map-reduce/"/>





  <title>MapReduce使用 | Ilivoo`s blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ilivoo`s blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/04/26/hadoop-map-reduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MapReduce使用</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-26T14:42:39+08:00">
                2017-04-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/MapReduce/" itemprop="url" rel="index">
                    <span itemprop="name">MapReduce</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4,619
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><ol>
<li>MapReduce是一个简单的计算处理框架, 它能够在一个廉价的大型集群上以一种容错的方式并行的处理TB级的数据。</li>
<li><p>一个MapRecude任务通常讲输入数据集进行分块, 并且以完全并行的方式处理map任务, 框架对map任务输出进行。排序, 并作为reduce任务的输入, 通常任务的输入和输出都存储在文件系统, 框架负责处理协调、监控并重运行失败的任务。</p>
</li>
<li><p>通常情况下计算节点和存储节点都是在同一个HDFS(如果MapReduce以HDFS作为文件系统)的datenode中， 这种<br>配置允许框架能够有效的协调任务在已经存在数据的节点中运行，这通常在集群中对网络带宽非常友好。</p>
</li>
<li>MapReduce也可以通过yarn（分布式资源协调工具）来运行， 并且为每一个MapReduce任务创建一个MRAppMaster负责从yarn的ResourceManager申请协调资源和对MapReduce任务进行监控和管理。</li>
<li>最小的一个MapReduce任务由一个输入输出、实现特定接口的map和reduce方法、以及一个job配置， job客户端提交任务， ResouceManager对任务进行协调监控并提供诊断信息给客户端。</li>
<li>虽然Hadoop框架是使用java运行， 但是MapReduce应用却不要求一定使用java编写， 如Hadoop Streaming允许用户使用任何可执行的shell（能够在shell命令中执行） 创建并运行mapper或者reducer， Hadoop Pipes以一个SWIG兼容的C++ API来实现MapReduce任务（而不是基于JNI）</li>
</ol>
<h4 id="输入和输出"><a href="#输入和输出" class="headerlink" title="输入和输出"></a>输入和输出</h4><ol>
<li>MapReduce框架操作唯一的&lt;key, value&gt;对，框架输入&lt;key, value&gt;对， 并产生&lt;key, value&gt;对作为输出，key和value需要在框架中通过RPC或者文件的方式进行传输， 所以必须序列化， 框架提供Writable接口作为序列化的基础， 另外框架需要通过key来对&lt;key, value&gt;对进行排序， 所以必须实现WritableComparable接口， 虽然key没有要求必须实现hashcode方法， 但是map任务后的reduce任务通常需要对&lt;key, value&gt;行partition， 而通过hash来进行partition却是默认的方式。</li>
</ol>
<h4 id="简单的例子"><a href="#简单的例子" class="headerlink" title="简单的例子"></a>简单的例子</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span></span></span><br><span class="line"><span class="class">       <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</span><br><span class="line">    <span class="comment">//创建单实例的对象， 减少对象的创建</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                    )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      <span class="comment">//输入的key其实是一个相对于文件的偏移量， value为每一行的数据</span></span><br><span class="line">      <span class="comment">//所以读取文件必须有一个格式， 并且讲文件split给每个map任务，这里由InputFormat提供</span></span><br><span class="line">      StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</span><br><span class="line">      <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">        word.set(itr.nextToken());</span><br><span class="line">        context.write(word, one);<span class="comment">//将split的单词和数量输出&lt;workd, count&gt;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span></span></span><br><span class="line"><span class="class">       <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">                       Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                       )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">        sum += val.get();</span><br><span class="line">      &#125;</span><br><span class="line">      result.set(sum);</span><br><span class="line">      context.write(key, result);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    Job job = Job.getInstance(conf, <span class="string">"word count"</span>);</span><br><span class="line">    job.setJarByClass(WordCount.class);</span><br><span class="line">    job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">    <span class="comment">//指定Combiner进行本地Reducer任务执行， 主要是这里的reducer任务具有操作无序性质， 所以</span></span><br><span class="line">    <span class="comment">//本地的reducer一般用来减小mapper到reducer的带宽， 对于速度上可能并不明显</span></span><br><span class="line">    job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">    job.setReducerClass(IntSumReducer.class);</span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line">    <span class="comment">//等待任务完成， 返回job客户端， 也可以执行返回</span></span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行应用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar wc.jar WordCount /user/joe/wordcount/input /user/joe/wordcount/output</span><br></pre></td></tr></table></figure></p>
<p>为MapReduce任务提供ClassPath和work dir提供资源<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar hadoop-mapreduce-examples-&lt;ver&gt;.jar wordcount -files dir1/dict.txt#dict1,dir2/dict.txt#dict2 -archives mytar.tgz#tgzdir input output</span><br></pre></td></tr></table></figure></p>
<p><em>说明：</em> -files 提供文件到任务work dir中， 通过逗号分割， 使用#号取别名, -archives 提供文件并且解压缩到work dir， 通过都好分割， 使用#号取别名， 两者指定的文件可以在MapReduce任务中获取</p>
<h4 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h4><ol>
<li>Hadoop MapReduce通过InputFormat将输入的files进行split并创建一任意个InputSplit，并为每个InputSplit创建一个map任务用来执行这个InputSplit表示的逻辑文件， map任务通过RecordReader来读取InputSplit这个逻辑文件， 并生成map的输入对&lt;key1, value1&gt;, InputSplit和RecordReader都是由InputFormat创建。</li>
<li><p>Mapper类是执行map任务的核心， 它循环的执行RecordReader产生的&lt;key1, value1&gt;对， 并且在执行任何的&lt;key1, value1&gt;对之前可以对Mapper进行初始化操作，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Mapper.setup(Context)</span><br><span class="line">Mapper.run(Context) # 用于提供map操作的模板方法， Mapper调用的方法</span><br><span class="line">Mapper.map(key, value, Context)</span><br><span class="line">Mapper.cleanup(Context)</span><br></pre></td></tr></table></figure>
</li>
<li><p>MapReduce 输出对不需要和输入对有任何的联系， 输入对可以map出零个或者多个输出对， 通过<code>context.write()</code>输出。</p>
</li>
<li>用户可以指定combiner对mapper产生的输出进行聚合， 这样可能会加快速度和减少网络带宽， 其实combiner就是一个reducer， 只是它单纯的对当前map任务的所有输出进行reduce任务操作， 操作完成之后再传给总的reduce来进行处理， 所以可以看到此处的reduce任务必须具有无序性， 其次reducer也可以接受并非只是mapper的中间结果&lt;key2, value2&gt;, 也可以接受&lt;key2, [value2, vlaue3…]&gt;</li>
<li>map任务的个数通常是通过输入文件的总大小，也就是总的输入文件的块， 正确的并发map任务通常每个节点10-100个， 通常对于轻量级cpu任务开启300个map任务， 因为一般情况下map需要从磁盘获取数据， 并进行简单操作， 所以通常都是io密集型而对cpu不敏感， map任务的创建需要时间， 所以最好map任务执行超过一分钟。</li>
</ol>
<h4 id="Partitioner"><a href="#Partitioner" class="headerlink" title="Partitioner"></a>Partitioner</h4><ol>
<li>Partitioner是用map产生的中间结果&lt;key1, value1&gt;的key空间来对每个map任务的的中间结果进行分区的， 通常情况下是通过hash来进行分区， 总的分区数量和reduce任务的分区数量是一样的。</li>
</ol>
<h4 id="Reducer"><a href="#Reducer" class="headerlink" title="Reducer"></a>Reducer</h4><p>Reducer 用来reduce Mapper任务产生的中间结果， 当Mapper产生结果后， 通过Partitioner将具体&lt;key2, value2&gt;或者是&lt;key2, [vlaue2, value3…]&gt;(经过combiner之后的结果)传输到具体的Reducer当中， 具体的某个Reducer收到所有Mapper需要传输到自己的&lt;key2, value2/[value2, value3…]&gt;之后， 对其进行shuffle、sort和最终的reduce</p>
<ol>
<li>Shuffle 讲所有从Mapper中获取的结果进行shuffle成&lt;value2, [value2, value3…]&gt;</li>
<li>Sort 对shuffle结果进行排序，shuffle和sort是同时进行的， 排序方式可以通过<code>Job.setSortComparatorClass(Class)</code>来提供， 此处是对key进行排序</li>
<li>Secondary Sort 如果需要对相同key的values进行排序可以指定<code>Job.setGroupingComparatorClass(Class)</code>来对value进行排序</li>
<li>Reduce 对当前Reducer收到并处理的&lt;key2, [value2, value3…]&gt;进行reduce操作， 用来产生&lt;key3, value3&gt;输出到文件系统中，reduce输出没有排序。reduce在操作之前和之后可以和map进行相同的初始化或者结束回调。</li>
<li>reduce的数量通常在[0.95~1.75] <em> <num of="" nodes=""> </num></em> <num of="" max="" container="" per="" node=""> 之间， 当maps任务执行完后， 指定倍数为0.95时所有的reducers可以立即启动并且执行传输map的输出， 当为1.75时最快的节点将会完成它们第一轮并且执行第二轮， 有助于负载均衡。 增加的reduces的数量虽然增加了负载， 但是增加了负载均衡的能力， 并且减小了失败造成的消耗。</num></li>
</ol>
<h4 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h4><p>Counter 是一个用来报告统计的基础设施， Mapper和Reducer实现可以使用Counter来报告统计信息。</p>
<h4 id="Job-Configuration"><a href="#Job-Configuration" class="headerlink" title="Job Configuration"></a>Job Configuration</h4><ol>
<li>Job代表一个MapReduce的任务配置， 通常用来配置InputFormat、Mapper、combiner（如果有）、Partitioner、Reducer、OutputFormat的实现</li>
<li><p>FileInputFormat和FileOutpuFormat配置输入和输出格式</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.setInputPaths(Job, Path…) FileInputFormat.addInputPath(Job, Path)</span><br><span class="line">FileInputFormat.setInputPaths(Job, String…) FileInputFormat.addInputPaths(Job, String)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Job通常需要指定先进的参数， 如Comparator、文件put到DistributedCache、是否使用compressed、是否speculative执行以及map和reduce最大的attempts</p>
</li>
<li>当然Job还可以使用Configuration的get/set来获取和设置更多的参数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Configuration.set(String, String)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="任务执行和环境变量"><a href="#任务执行和环境变量" class="headerlink" title="任务执行和环境变量"></a>任务执行和环境变量</h4><ol>
<li>MRAppMaster使用隔离jvm的一个子进程去执行Mapper/Reducer任务， 子进程继承父进程的环境变量， 用户可以指定额外的子进程虚拟机启动参数，如下：<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- @taskid@ 表示MapReduce任务id--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">  -Xmx512M -Djava.library.path=/home/mycompany/lib -verbose:gc -Xloggc:/tmp/@taskid@.gc</span><br><span class="line">  -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false</span><br><span class="line">  <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">  -Xmx1024M -Djava.library.path=/home/mycompany/lib -verbose:gc -Xloggc:/tmp/@taskid@.gc</span><br><span class="line">  -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false</span><br><span class="line">  <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="任务提交和监控"><a href="#任务提交和监控" class="headerlink" title="任务提交和监控"></a>任务提交和监控</h4><ol>
<li>Job是一个原始的接口， 用于用户job与ResourceManager交互， Job提供的基本功能是提交任务、跟踪任务进程、访问任务的报告和日志和获取MapRecude集群状态等信息， job提交任务涉及到下面几个方面：<ul>
<li>检查任务的输入输出</li>
<li>计算InputFormat的InputSplit</li>
<li>为任务分布式缓存设置必要的账号信息</li>
<li>复制任务jar和配置信息到MapReduce系统目录</li>
<li>提交任务到ResourceManager并选择是否监控它的状态</li>
</ul>
</li>
<li><p>任务历史日志记录在两个指定的目录当中， 如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mapreduce.jobhistory.intermediate-done-dir</span><br><span class="line">mapreduce.jobhistory.done-dir</span><br></pre></td></tr></table></figure>
</li>
<li><p>用户可以查看任务运行历史日志总览</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mapred job -history [all] output.jhist</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="Job-输入"><a href="#Job-输入" class="headerlink" title="Job 输入"></a>Job 输入</h4><ol>
<li>InputFormat 描述MapReduce任务的输入，主要功能如下：<ul>
<li>验证任务输入</li>
<li>split 所有的输入文件为逻辑的InputSplit实例， 每一个InputSplit相当于一个Mapper任务</li>
<li>提供RecordReader实现， 用于Mapper任务启动时从InputSplit中获取单个&lt;key1, value1&gt;记录</li>
</ul>
</li>
<li>默认基于文件的输入是FileInputFortmat， 它通过总文件大小来split出逻辑的InputSplit， 显然通过总大小来分割有时候是无效的， 因为RecordReader无法获取记录的边界</li>
</ol>
<h4 id="Job输出"><a href="#Job输出" class="headerlink" title="Job输出"></a>Job输出</h4><ol>
<li>OutputFormat 描述MapReduce任务的输出， 主要功能如下：<ul>
<li>验证任务输出， 如：检查输出文件是否存在</li>
<li>提供RecorderWriter实现， 用于写入任务输出， Output文件存储到文件系统</li>
</ul>
</li>
<li>OutputCommiter 描述MapReduce任务输出提交， OutputCommiter的主要功能如下：<ul>
<li>初始化设置， 如：为任务创建临时输出目录， 任务的初始化设置是在单独的任务中完成的， 初始化之前任务处在<code>PREP</code>状态， 初始化完成后处在<code>RUNNING</code>状态</li>
<li>任务完成后的清理动作， 如：删除零时输出目录， 任务的清理工作也是在单独的任务中， 清理工作完成后任务可能出现<code>SUCCEDED/FAILED/KILLED</code>状态</li>
<li>检查任务是否需要提交</li>
<li>一旦任务完成就提交任务的输出</li>
<li>如果任务失败， 任务输出将会被清理， 并且丢弃任务提交， 如果任务不能清理， 一个相同attempt-id的任务将会单独启动并执行清理动作</li>
</ul>
</li>
<li>RecordWriter 负责讲Reducer的输出&lt;key3, value3&gt;输出到文件系统， 并且负责讲job的outputs输出到文件系统</li>
</ol>
<h4 id="提交Job到队列"><a href="#提交Job到队列" class="headerlink" title="提交Job到队列"></a>提交Job到队列</h4><ol>
<li>用户提交任务到队列当中， 队列作为一个任务集合允许系统提供指定的功能， 如队列使用ACLs控制那个用户可以提交任务到队列， 在Hadoop中默认就是使用队列作为调度器来调度任务。</li>
<li>Hadoop中存在一个叫做default的队列用于用户默认的任务提交队列， 用户也可以通过<code>Configuration.set(MRJobConfig.QUEUE_NAME, String)</code>指定将任务提交到特定名字的队列当中， 并且Hadoop还提供了一个可插拔的<code>Capacity Scheduler</code>用来支持多租户， 提供资源的隔离， 所以它存在多个队列。</li>
</ol>
<h4 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h4><ol>
<li>Counters代表全局的计数器， 可以被MapReduce框架或者应用定义， 每一个Counter可以是一个Enum， 特定的Enum的Counter被集中到特定的Counters.Group当中， 应用可以定义任意的Enum并且<code>Counter.incrCounter(Enum, long)</code>或者<code>Counter.incrCounter(String, String, long)</code>到map或者reduce方法当中， 这些counters被框架自动聚合。</li>
</ol>
<h4 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h4><ol>
<li>分布式的缓存用于有效的存储特定应用大型只读的文件， 它是被MapReduce框架提供的基础设施用于缓存应用需要的文本、归档和jar文件等等</li>
<li>Job中的应用通过<code>hdfs://</code>指定被缓的文件， 分布式的缓存假设被指定<code>hdfs://</code>的文件已经存在于文件系统当中</li>
<li>框架将会在任何任务被执行之前，复制必须的文件到worker节点， 事实上它是相当有效的， 文件只会被复制一次， 并且un-archive到work节点</li>
<li>分布式的缓存跟踪缓存文件的修改时间戳， 显然分布式的缓存文件是不能被任何的修改</li>
<li>文件、归档、jar/native lib都可以被缓存， 可以通过property设置， 或者通过Job添加， 如：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Job.addCacheFile(URI) / Job.addCacheArchive(URI)</span><br><span class="line">Job.AddArchiveToClassPath(Path) / JOb.addFileToClassPath(Path)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>URI: hdfs://host:port/absolute-path#link-name</p>
<ol start="6">
<li>分布式的缓存文件可以是私有或公用， 这决定了它们是怎样被worker节点所共享的， 主要是通过分布式文件的用户和文件的可见性来决定</li>
</ol>
<p>####　Debugging</p>
<ol>
<li>MapReduce框架提供当任务失败时执行用户指定脚本的功能， 脚本可以访问任务的标准输出、标准错误、系统日志和任务配置， 脚本处理访问的信息并输出错误信息到控制台或者任务UI</li>
<li>Debugging脚本的使用步骤：<ul>
<li>提交脚本到分布式缓存中</li>
<li>提交脚本到map或者reduce当中， 使用property或者Configuration</li>
<li>脚本访问 $script $stdout $stderr $syslog $jobconf</li>
</ul>
</li>
</ol>
<h4 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h4><ol>
<li>MapReduce提供map和reduce应用输出压缩功能， 为了性能它使用本地实现</li>
</ol>
<h4 id="跳过错误的记录"><a href="#跳过错误的记录" class="headerlink" title="跳过错误的记录"></a>跳过错误的记录</h4><ol>
<li>Hadoop可以通过<code>ShipBadRecords</code>类来控制map输入的错误记录， 对于某些应用来说如果少量的错误记录是可以接受的那么可以开启此功能， 使用<code>SkipBadRecords.set[Mapper|Reducer]MaxSkipGroups(Configuration, long)</code>来设置最大的错误记录数量。</li>
</ol>
<h4 id="复杂的例子"><a href="#复杂的例子" class="headerlink" title="复杂的例子"></a>复杂的例子</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.FileReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.HashSet;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Counter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.StringUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount2</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span></span></span><br><span class="line"><span class="class">       <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</span><br><span class="line">    <span class="comment">// 提供counter功能</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">enum</span> CountersEnum &#123; INPUT_WORDS &#125;</span><br><span class="line">    <span class="comment">// 减少对象的创建</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line">    <span class="comment">// 提供单词大小写敏感和模式忽略功能</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> caseSensitive;</span><br><span class="line">    <span class="keyword">private</span> Set&lt;String&gt; patternsToSkip = <span class="keyword">new</span> HashSet&lt;String&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Configuration conf;</span><br><span class="line">    <span class="keyword">private</span> BufferedReader fis;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在setup中处理Mapper的初始化动作</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">        InterruptedException </span>&#123;</span><br><span class="line">      <span class="comment">// 获取配置</span></span><br><span class="line">      conf = context.getConfiguration();</span><br><span class="line">      <span class="comment">// 获取Job中设置的环境变量</span></span><br><span class="line">      caseSensitive = conf.getBoolean(<span class="string">"wordcount.case.sensitive"</span>, <span class="keyword">true</span>);</span><br><span class="line">      <span class="comment">// 解析配置</span></span><br><span class="line">      <span class="keyword">if</span> (conf.getBoolean(<span class="string">"wordcount.skip.patterns"</span>, <span class="keyword">false</span>)) &#123;</span><br><span class="line">        <span class="comment">//获取并解析缓存</span></span><br><span class="line">        URI[] patternsURIs = Job.getInstance(conf).getCacheFiles();</span><br><span class="line">        <span class="keyword">for</span> (URI patternsURI : patternsURIs) &#123;</span><br><span class="line">          Path patternsPath = <span class="keyword">new</span> Path(patternsURI.getPath());</span><br><span class="line">          String patternsFileName = patternsPath.getName().toString();</span><br><span class="line">          parseSkipFile(patternsFileName);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">parseSkipFile</span><span class="params">(String fileName)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        fis = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(fileName));</span><br><span class="line">        String pattern = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> ((pattern = fis.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">          patternsToSkip.add(pattern);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">        System.err.println(<span class="string">"Caught exception while parsing the cached file '"</span></span><br><span class="line">            + StringUtils.stringifyException(ioe));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                    )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      <span class="comment">// 处理单词大小写敏感和模式忽略功能</span></span><br><span class="line">      String line = (caseSensitive) ?</span><br><span class="line">          value.toString() : value.toString().toLowerCase();</span><br><span class="line">      <span class="keyword">for</span> (String pattern : patternsToSkip) &#123;</span><br><span class="line">        line = line.replaceAll(pattern, <span class="string">""</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(line);</span><br><span class="line">      <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">        word.set(itr.nextToken());</span><br><span class="line">        context.write(word, one);</span><br><span class="line">        <span class="comment">// counter计数， 会在日志中打印</span></span><br><span class="line">        Counter counter = context.getCounter(CountersEnum.class.getName(),</span><br><span class="line">            CountersEnum.INPUT_WORDS.toString());</span><br><span class="line">        counter.increment(<span class="number">1</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span></span></span><br><span class="line"><span class="class">       <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">                       Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                       )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">        sum += val.get();</span><br><span class="line">      &#125;</span><br><span class="line">      result.set(sum);</span><br><span class="line">      context.write(key, result);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="comment">// 配置解析</span></span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    GenericOptionsParser optionParser = <span class="keyword">new</span> GenericOptionsParser(conf, args);</span><br><span class="line">    String[] remainingArgs = optionParser.getRemainingArgs();</span><br><span class="line">    <span class="keyword">if</span> ((remainingArgs.length != <span class="number">2</span>) &amp;&amp; (remainingArgs.length != <span class="number">4</span>)) &#123;</span><br><span class="line">      System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; &lt;out&gt; [-skip skipPatternFile]"</span>);</span><br><span class="line">      System.exit(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Job job = Job.getInstance(conf, <span class="string">"word count"</span>);</span><br><span class="line">    <span class="comment">// 基本设置</span></span><br><span class="line">    job.setJarByClass(WordCount2.class);</span><br><span class="line">    job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">    job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">    job.setReducerClass(IntSumReducer.class);</span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">    List&lt;String&gt; otherArgs = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; remainingArgs.length; ++i) &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="string">"-skip"</span>.equals(remainingArgs[i])) &#123;</span><br><span class="line">        <span class="comment">// 设置缓存</span></span><br><span class="line">        job.addCacheFile(<span class="keyword">new</span> Path(remainingArgs[++i]).toUri());</span><br><span class="line">        <span class="comment">// 设置环境变量</span></span><br><span class="line">        job.getConfiguration().setBoolean(<span class="string">"wordcount.skip.patterns"</span>, <span class="keyword">true</span>);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        otherArgs.add(remainingArgs[i]);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 设置输入与输出</span></span><br><span class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs.get(<span class="number">0</span>)));</span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs.get(<span class="number">1</span>)));</span><br><span class="line"></span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>命令行执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -ls /user/joe/wordcount/input/</span><br><span class="line">/user/joe/wordcount/input/file01</span><br><span class="line">/user/joe/wordcount/input/file02</span><br><span class="line"></span><br><span class="line">$ bin/hadoop fs -cat /user/joe/wordcount/input/file01</span><br><span class="line">Hello World, Bye World!</span><br><span class="line"></span><br><span class="line">$ bin/hadoop fs -cat /user/joe/wordcount/input/file02</span><br><span class="line">Hello Hadoop, Goodbye to hadoop.</span><br><span class="line"></span><br><span class="line">$ bin/hadoop fs -cat /user/joe/wordcount/patterns.txt</span><br><span class="line">\.</span><br><span class="line">\,</span><br><span class="line">\!</span><br><span class="line">to</span><br><span class="line"></span><br><span class="line">$ bin/hadoop jar wc.jar WordCount2 -Dwordcount.case.sensitive=false /user/joe/wordcount/input /user/joe/wordcount/output -skip /user/joe/wordcount/patterns.txt</span><br><span class="line"></span><br><span class="line">$ bin/hadoop fs -cat /user/joe/wordcount/output/part-r-00000</span><br><span class="line">bye 1</span><br><span class="line">goodbye 1</span><br><span class="line">hadoop 2</span><br><span class="line">hello 2</span><br><span class="line">horld 2</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <div>
        
            <div style="text-align:center;color: #ccc;font-size:14px;">------ 本文结束------</div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          
            <a href="/tags/MapReduce/" rel="tag"># MapReduce</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/04/26/docker-dockerfile/" rel="next" title="Dockerfile 详解">
                <i class="fa fa-chevron-left"></i> Dockerfile 详解
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/04/28/linux-ubuntu-setup/" rel="prev" title="linux安装配置">
                linux安装配置 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/my-icon.jpeg"
                alt="ilivoo" />
            
              <p class="site-author-name" itemprop="name">ilivoo</p>
              <p class="site-description motion-element" itemprop="description">我，在這裡，享受等你的時光。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">48</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#概述"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#输入和输出"><span class="nav-number">2.</span> <span class="nav-text">输入和输出</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#简单的例子"><span class="nav-number">3.</span> <span class="nav-text">简单的例子</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mapper"><span class="nav-number">4.</span> <span class="nav-text">Mapper</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Partitioner"><span class="nav-number">5.</span> <span class="nav-text">Partitioner</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reducer"><span class="nav-number">6.</span> <span class="nav-text">Reducer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Counter"><span class="nav-number">7.</span> <span class="nav-text">Counter</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Job-Configuration"><span class="nav-number">8.</span> <span class="nav-text">Job Configuration</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#任务执行和环境变量"><span class="nav-number">9.</span> <span class="nav-text">任务执行和环境变量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#任务提交和监控"><span class="nav-number">10.</span> <span class="nav-text">任务提交和监控</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Job-输入"><span class="nav-number">11.</span> <span class="nav-text">Job 输入</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Job输出"><span class="nav-number">12.</span> <span class="nav-text">Job输出</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#提交Job到队列"><span class="nav-number">13.</span> <span class="nav-text">提交Job到队列</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#计数器"><span class="nav-number">14.</span> <span class="nav-text">计数器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分布式缓存"><span class="nav-number">15.</span> <span class="nav-text">分布式缓存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据压缩"><span class="nav-number">16.</span> <span class="nav-text">数据压缩</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#跳过错误的记录"><span class="nav-number">17.</span> <span class="nav-text">跳过错误的记录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#复杂的例子"><span class="nav-number">18.</span> <span class="nav-text">复杂的例子</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ilivoo</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

  <script type="text/javascript" src="/lib/clipboard/clipboard.js"></script>
<script type="text/javascript" src="/js/src/custom.js"></script>

</body>
</html>
