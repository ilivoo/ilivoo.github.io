<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="Ilivoo`s blog" type="application/atom+xml" />






<meta name="description" content="我，在這裡，享受等你的時光。">
<meta property="og:type" content="website">
<meta property="og:title" content="Ilivoo`s blog">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Ilivoo`s blog">
<meta property="og:description" content="我，在這裡，享受等你的時光。">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ilivoo`s blog">
<meta name="twitter:description" content="我，在這裡，享受等你的時光。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>Ilivoo`s blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ilivoo`s blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/26/tools-tmux/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/26/tools-tmux/" itemprop="url">tmux安装与使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-26T17:36:25+08:00">
                2019-09-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/" itemprop="url" rel="index">
                    <span itemprop="name">tools</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,416
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><p>安装tmux</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/gpakosz/.tmux</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置tmux</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">set-option -g allow-rename off</span><br><span class="line">每一次窗口执行不同的命令窗口的名字就会发生变化， 此处是关闭自动命名</span><br><span class="line">set-window-option -g pane-base-index 1</span><br><span class="line">设置窗口pane的下标从1开始</span><br><span class="line"># on Linux, this requires xsel or xclip</span><br><span class="line">tmux_conf_copy_to_os_clipboard=true</span><br><span class="line">设置tmux剪切板与系统剪切板同步</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用tmux</p>
<ol>
<li><p>tmux使用来管理回话并提供分屏等功能的软件， 当tmux开启时， 就会启动一个tmux-server的程序，用来管理上面所有的session会话， 每个session会话中可以存在多个windows（窗口）， 每个窗口又存在多个panel（面板）</p>
</li>
<li><p>tmux命令</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tmux + tab				列出所有tmux可以使用的命令</span><br><span class="line">tmux new-session -s name		创建session</span><br><span class="line">tmux list-session			查看session</span><br><span class="line">tmux attach-session name	attach到某个session</span><br><span class="line">tmux detach					脱离某个session</span><br><span class="line">tmux kill-session name		杀死某个session</span><br><span class="line">tmux info 				查看session, window, pane, 运行的进程号</span><br><span class="line">tmux list-keys 				列出所有可以的快捷键和其运行的 tmux 命令</span><br><span class="line">tmux list-commands 		列出所有的 tmux 命令及其参数</span><br><span class="line">tmux kill-server 关闭所有 session</span><br></pre></td></tr></table></figure>
<p> <em>注意</em> 所有的上面这些命令在没进入某个session之前直接使用tmux command args来调用， 当进如了tmux之后直接在任何的panel中通过 <code>&lt;pre&gt; + : +command args</code>来激活命令行操作， 此时所有的命令只需要使用 command args就可以调用了</p>
</li>
<li><p>tmux 基本操作</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">? 列出所有快捷键；按q返回</span><br><span class="line">d 脱离当前会话,可暂时返回Shell界面</span><br><span class="line">s 选择并切换会话；在同时开启了多个会话时使用</span><br><span class="line">: 进入命令行模式；此时可输入支持的命令，例如 kill-server 关闭所有tmux会话, rename 重命名当前session</span><br><span class="line">[ 复制模式，光标移动到复制内容位置，空格键开始，方向键选择复制，回车确认，q/Esc退出， 可以设置vi模式复制</span><br><span class="line">] 进入粘贴模式，粘贴之前复制的内容，按q/Esc退出</span><br><span class="line">t 显示当前的时间</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ol>
<pre><code>4. tmux 会话操作

    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">:new        启动新会话</span><br><span class="line">s           列出所有会话</span><br><span class="line">$           重命名当前会话</span><br></pre></td></tr></table></figure>


5. tmux 窗口操作

    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">c 创建新窗口</span><br><span class="line">&amp; 关闭当前窗口</span><br><span class="line">[0-9] 数字键切换到指定窗口</span><br><span class="line">ctrl + h/l 左右切换窗口（按住ctrl， 并快速的按h/l）</span><br><span class="line">w 通过窗口列表切换窗口</span><br><span class="line">, 重命名当前窗口，便于识别</span><br><span class="line">. 修改当前窗口编号，相当于重新排序</span><br><span class="line">f 在所有窗口中查找关键词，便于窗口多了切换</span><br><span class="line"></span><br><span class="line">swap-window -s 3 -t 1  交换 3 号和 1 号窗口</span><br><span class="line">swap-window -t 1       交换当前和 1 号窗口</span><br><span class="line">move-window -t 1       移动当前窗口到 1 号</span><br></pre></td></tr></table></figure>


    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tmux new-window				添加一个window</span><br><span class="line">tmux select-window -t 0		选择第0个窗口</span><br><span class="line">tmux kill-window -t 1		杀死某个窗口</span><br></pre></td></tr></table></figure>


6. tmux 面板操作

    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&quot;/- 将当前面板上下分屏</span><br><span class="line">%/_ 将当前面板左右分屏</span><br><span class="line">x 关闭当前分屏</span><br><span class="line">! 将当前面板置于新窗口,即新建一个窗口,其中仅包含当前面板</span><br><span class="line">z 最大化当前所在面板</span><br><span class="line">ctrl+方向键 以1个单元格为单位移动边缘以调整当前面板大小</span><br><span class="line">alt+方向键 以5个单元格为单位移动边缘以调整当前面板大小</span><br><span class="line">H/J/K/L 以1个单元格移动边缘以调整当前面板大小</span><br><span class="line">q 显示面板编号</span><br><span class="line">o 选择当前窗口中下一个面板</span><br><span class="line">方向键/h/j/k/l 移动光标选择对应面板</span><br><span class="line">&#123; 向前置换当前面板</span><br><span class="line">&#125; 向后置换当前面板</span><br><span class="line">alt+o 逆时针旋转当前窗口的面板</span><br><span class="line">ctrl+o 顺时针旋转当前窗口的面板</span><br></pre></td></tr></table></figure>


7. tmux 滚屏操作，由于tmux接管如果输出大量的数据无法看到上面屏幕的字， 如果此时鼠标操作关闭，那么当使用鼠标滑轮的时候显示的执行过命令的显示， 而不能屏幕翻页， 要想达到这个目的有两个办法：
    <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">打开鼠标操作， 使用滑轮上下翻页 &lt;pre&gt; + m</span><br><span class="line">打开复制模式， 使用vi的翻滚策略来操作， 此时又会碰到一个问题， 如果前缀是ctrl + b那么不好往下整页翻滚， 建议使用半屏翻滚 ctrl + u / d(f)</span><br></pre></td></tr></table></figure>


8. 复制模式

   按下 `PREFIX-[` 进入文本复制模式。可以使用方向键在屏幕中移动光标。默认情况下，方向键是启用的。在配置文件中启用 Vim 键盘布局来切换窗口、调整窗格大小。Tmux 也支持 Vi 模式。要是想启用 Vi 模式，只需要把下面这一行添加到 .tmux.conf 中：

   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setw -g mode-keys vi</span><br></pre></td></tr></table></figure>


   启用这条配置后，就可以使用 h、j、k、l 来移动光标了。

   想要退出文本复制模式的话，按下回车键就可以了。

   然后按下 `PREFIX-]` 粘贴刚才复制的文本。

   一次移动一格效率低下，在 Vi 模式启用的情况下，可以辅助一些别的快捷键高效工作。

   例如，可以使用 w 键逐词移动，使用 b 键逐词回退。使用 f 键加上任意字符跳转到当前行第一次出现该字符的位置，使用 F 键达到相反的效果。
</code></pre>
          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/26/tools-zsh/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/26/tools-zsh/" itemprop="url">zsh安装与使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-26T17:34:15+08:00">
                2019-09-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  178
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><p>安装zsh</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install zsh    #安装zsh</span><br><span class="line">chsh -s /bin/zsh            #不需要sudo，重启</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装oh-my-zsh</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/robbyrussell/oh-my-zsh</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装zsh插件</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vi-mode</span><br><span class="line">autojump 				        需要安装软件</span><br><span class="line">zsh-autosuggestions 	  https://github.com/zsh-users/zsh-autosuggestions</span><br><span class="line">last-working-dir        </span><br><span class="line">d						            在终端输入d 显示最近频繁进入的路径，然后输入路径前对应的序号可快速进入对应路径</span><br><span class="line">history					        用法：在终端输入h即可</span><br><span class="line">zsh-syntax-highlighting	https://github.com/zsh-users/zsh-syntax-highlighting</span><br><span class="line">web-search				      如：google StackOverflow， 指定搜搜引擎就可以了</span><br><span class="line">sublime					        需要安装软件， [s]st [|文件|文件夹] [管理员]打开 [当前目录|文件|文件夹]</span><br></pre></td></tr></table></figure>
</li>
</ol>

          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/26/tools-vim/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/26/tools-vim/" itemprop="url">vim 安装和使用技巧</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-26T17:25:06+08:00">
                2019-09-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/" itemprop="url" rel="index">
                    <span itemprop="name">tools</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,167
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="vim使用"><a href="#vim使用" class="headerlink" title="vim使用"></a>vim使用</h4><ul>
<li><p>16进制编辑</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">使用vim 打开需要编辑的文件， 如： Hello.class</span><br><span class="line">	vim -b Hello.class</span><br><span class="line">进入xxd转换程序模式</span><br><span class="line">	:%!xxd</span><br><span class="line">查找并修改文件16进制部分</span><br><span class="line">退出xxd转换程序模式（必须退出， 不然以xxd显示进行保存）</span><br><span class="line">	:%!xxd -r</span><br><span class="line">推出vim</span><br><span class="line">	:wq</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="原生vim"><a href="#原生vim" class="headerlink" title="原生vim"></a>原生vim</h4><ol>
<li>更新vim到最新版本 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:jonathonf/vim</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="2">
<li>安装vim <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/amix/vimrc</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="3">
<li><p>添加自动更新到crontab中</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 */6 * * * cd /home/feng/.vim_runtime &amp;&amp; git pull --rebase &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="4">
<li><p>插件快捷键讲解</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ack.vim         内容搜索      &lt;leader&gt; + g</span><br><span class="line">ctrlp.vim       文件搜索      &lt;leader&gt; + j</span><br><span class="line">bufexplorer.zip 缓存查看      &lt;leader&gt; + o</span><br><span class="line">mru.vim         最近文件      &lt;leader&gt; + f</span><br><span class="line">NERD Tree       文件目录      &lt;leader&gt; + nn</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="使用neovim-vim的替代品-推荐"><a href="#使用neovim-vim的替代品-推荐" class="headerlink" title="使用neovim(vim的替代品,推荐)"></a>使用neovim(vim的替代品,推荐)</h4><ol>
<li><p>安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install software-properties-common</span><br><span class="line">sudo add-apt-repository ppa:neovim-ppa/stable</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install neovim</span><br><span class="line">sudo apt-get install python-dev python-pip python3-dev python3-pip</span><br><span class="line">sudo update-alternatives --install /usr/bin/vi vi /usr/bin/nvim 60</span><br><span class="line">sudo update-alternatives --config vi</span><br><span class="line">sudo update-alternatives --install /usr/bin/vim vim /usr/bin/nvim 60</span><br><span class="line">sudo update-alternatives --config vim</span><br><span class="line">sudo update-alternatives --install /usr/bin/editor editor /usr/bin/nvim 60</span><br><span class="line">sudo update-alternatives --config editor</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装插件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">curl -fLo ~/.vim/autoload/plug.vim --create-dirs \</span><br><span class="line">    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim</span><br><span class="line"></span><br><span class="line"># 将已有的 Vim 配置，用于 nvim</span><br><span class="line"># .vim 文件夹会存放插键相关内容，比如 vim-plug 的内容</span><br><span class="line">ln -s ~/.vim ~/.config/nvim</span><br><span class="line">ln -s ~/.vimrc ~/.config/nvim/init.vim</span><br><span class="line"></span><br><span class="line"># 安装插键</span><br><span class="line">:PlugInstall</span><br><span class="line"># 检查状态</span><br><span class="line">:PlugStatus</span><br><span class="line"># 删除插键（需要先将 ~/.config/nvim/init.vim 中注释掉相关插键）</span><br><span class="line">:PlugClean</span><br><span class="line"># 更新插键</span><br><span class="line">: PlugUpdate</span><br><span class="line"># 升级 vim-plug</span><br><span class="line">:PlugUpgrade</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol start="3">
<li><p>配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line">call plug#begin(&apos;~/.local/share/nvim/plugged&apos;)</span><br><span class="line">Plug &apos;vim-airline/vim-airline&apos;</span><br><span class="line">Plug &apos;majutsushi/tagbar&apos;</span><br><span class="line">Plug &apos;kien/ctrlp.vim&apos;</span><br><span class="line">Plug &apos;tacahiroy/ctrlp-funky&apos;</span><br><span class="line">Plug &apos;mileszs/ack.vim&apos;</span><br><span class="line">Plug &apos;yegappan/mru&apos;</span><br><span class="line">Plug &apos;ianva/vim-youdao-translater&apos;</span><br><span class="line">Plug &apos;yonchu/accelerated-smooth-scroll&apos;</span><br><span class="line">Plug &apos;jlanzarotta/bufexplorer&apos;</span><br><span class="line">Plug &apos;mhinz/vim-startify&apos;</span><br><span class="line">Plug &apos;scrooloose/nerdtree&apos;, &#123; &apos;on&apos;:  &apos;NERDTreeToggle&apos; &#125;</span><br><span class="line">Plug &apos;easymotion/vim-easymotion&apos;</span><br><span class="line">Plug &apos;Valloric/YouCompleteMe&apos;</span><br><span class="line">call plug#end()</span><br><span class="line"></span><br><span class="line">set nobackup</span><br><span class="line">set nowb</span><br><span class="line">set noswapfile</span><br><span class="line">&quot;set number</span><br><span class="line">nnoremap &lt;F5&gt; :set nonumber!&lt;CR&gt;:set foldcolumn=0&lt;CR&gt;  &lt;Paste&gt;</span><br><span class="line">set hlsearch</span><br><span class="line">set ignorecase</span><br><span class="line">set incsearch</span><br><span class="line">set smartcase</span><br><span class="line">filetype plugin indent on</span><br><span class="line">set tabstop=4</span><br><span class="line">set softtabstop=4</span><br><span class="line">set shiftwidth=4</span><br><span class="line">set expandtab</span><br><span class="line"></span><br><span class="line">&quot;快捷键的映射，通过不同的前缀定义快捷键在那种模式下启动</span><br><span class="line">&quot;nore前缀   非递归</span><br><span class="line">&quot;n前缀      普通实施生效</span><br><span class="line">&quot;v前缀      可视模式生效</span><br><span class="line">&quot;i前缀      插入模式生效</span><br><span class="line">&quot;c前缀      在EX命令模式生效</span><br><span class="line"></span><br><span class="line">&quot;定义前缀键</span><br><span class="line">:let mapleader=&quot;;&quot;</span><br><span class="line"></span><br><span class="line">&quot;定义NERDTree出发快捷键</span><br><span class="line">map &lt;F2&gt; :NERDTreeToggle&lt;CR&gt;</span><br><span class="line">autocmd bufenter * if (winnr(&quot;$&quot;) == 1 &amp;&amp; exists(&quot;b:NERDTree&quot;) &amp;&amp; b:NERDTree.isTabTree()) | q | endif</span><br><span class="line"></span><br><span class="line">&quot;定义文件结构快捷键</span><br><span class="line">nmap &lt;F3&gt; :TagbarToggle&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot;定义文件搜索相关</span><br><span class="line">&quot;let g:ctrlp_map = &apos;&lt;c-p&gt;&apos;</span><br><span class="line">let g:ctrlp_map = &apos;&lt;F8&gt;&apos;</span><br><span class="line">let g:ctrlp_cmd = &apos;CtrlP&apos;</span><br><span class="line">let g:ctrlp_working_path_mode = &apos;ra&apos;</span><br><span class="line">set wildignore+=*/tmp/*,*.so,*.swp,*.zip</span><br><span class="line">let g:ctrlp_custom_ignore = &#123;</span><br><span class="line">  \ &apos;dir&apos;:  &apos;\v[\/]\.(git|hg|svn)$&apos;,</span><br><span class="line">  \ &apos;file&apos;: &apos;\v\.(exe|so|dll)$&apos;,</span><br><span class="line">  \ &apos;link&apos;: &apos;some_bad_symbolic_links&apos;,</span><br><span class="line">  \ &#125;</span><br><span class="line">let g:ctrlp_user_command = [&apos;.git&apos;, &apos;cd %s &amp;&amp; git ls-files -co --exclude-standard&apos;]</span><br><span class="line">let g:ctrlp_working_path_mode=0</span><br><span class="line">let g:ctrlp_match_window_bottom=1</span><br><span class="line">let g:ctrlp_max_height=15</span><br><span class="line">let g:ctrlp_match_window_reversed=0</span><br><span class="line">let g:ctrlp_mruf_max=500</span><br><span class="line">let g:ctrlp_follow_symlinks=1</span><br><span class="line">&quot;ctrl + j/k 进行上下选择</span><br><span class="line">&quot;ctrl + x 在当前窗口水平分屏打开文件</span><br><span class="line">&quot;ctrl + v 同上, 垂直分屏</span><br><span class="line">&quot;ctrl + t 在tab中打开</span><br><span class="line"></span><br><span class="line">&quot;定义文件中搜索函数</span><br><span class="line">nnoremap &lt;Leader&gt;f :CtrlPFunky&lt;Cr&gt;</span><br><span class="line">nnoremap &lt;Leader&gt;fu :execute &apos;CtrlPFunky &apos; . expand(&apos;&lt;cword&gt;&apos;)&lt;Cr&gt;</span><br><span class="line">let g:ctrlp_funky_syntax_highlight = 1</span><br><span class="line">let g:ctrlp_extensions = [&apos;funky&apos;]</span><br><span class="line"></span><br><span class="line">&quot;定义内容搜索快捷键</span><br><span class="line">let g:ackprg = &apos;ag --nogroup --nocolor --column&apos;</span><br><span class="line">map &lt;F7&gt; :Ack&lt;space&gt;</span><br><span class="line">if executable(&apos;ag&apos;)</span><br><span class="line">  &quot; Use Ag over Grep</span><br><span class="line">  set grepprg=ag\ --nogroup\ --nocolor</span><br><span class="line"></span><br><span class="line">  &quot; Use ag in CtrlP for listing files. Lightning fast and respects .gitignore</span><br><span class="line">  let g:ctrlp_user_command = &apos;ag %s -l --nocolor -g &quot;&quot;&apos;</span><br><span class="line"></span><br><span class="line">  &quot; ag is fast enough that CtrlP doesn&apos;t need to cache</span><br><span class="line">  let g:ctrlp_use_caching = 0</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">&quot;定义缓冲文件快捷键</span><br><span class="line">nnoremap &lt;silent&gt; &lt;F9&gt; :BufExplorer&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot;定义最近文件快捷键</span><br><span class="line">nnoremap &lt;silent&gt; &lt;F10&gt; :MRU&lt;CR&gt;</span><br><span class="line">let MRU_Window_Height = 10</span><br><span class="line">&quot;jk          # 在历史记录列表中上下移动</span><br><span class="line">&quot;Enter       # 进入相应文件</span><br><span class="line">&quot;o       # 水平方向打开</span><br><span class="line">&quot;t           # 在新标签中打开历史文件</span><br><span class="line">&quot;u           # 更新文件列表</span><br><span class="line">&quot;q           # 退出MRU历史记录</span><br><span class="line">&quot;v           # 以只读模式打开</span><br><span class="line">&quot;/           # 在MRU列表中快速查找</span><br><span class="line"></span><br><span class="line">&quot;定义有道翻译快捷键</span><br><span class="line">vnoremap &lt;silent&gt; &lt;C-T&gt; :&lt;C-u&gt;Ydv&lt;CR&gt;</span><br><span class="line">nnoremap &lt;silent&gt; &lt;C-T&gt; :&lt;C-u&gt;Ydc&lt;CR&gt;</span><br><span class="line">noremap &lt;leader&gt;yd :&lt;C-u&gt;Yde&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot;定义跳转快捷键</span><br><span class="line">map  &lt;Leader&gt;w &lt;Plug&gt;(easymotion-bd-w)</span><br><span class="line">nmap &lt;Leader&gt;w &lt;Plug&gt;(easymotion-overwin-w)</span><br><span class="line"></span><br><span class="line">&quot;YouCompleteMe快捷键</span><br><span class="line">nnoremap &lt;leader&gt;gl :YcmCompleter GoToDeclaration&lt;CR&gt;</span><br><span class="line">nnoremap &lt;leader&gt;gf :YcmCompleter GoToDefinition&lt;CR&gt;</span><br><span class="line">nnoremap &lt;leader&gt;gg :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;</span><br></pre></td></tr></table></figure></li>
</ol>

          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/26/tools-sublime/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/26/tools-sublime/" itemprop="url">sublime安装与使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-26T17:32:08+08:00">
                2018-09-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/tools/" itemprop="url" rel="index">
                    <span itemprop="name">tools</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  187
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><p>安装直接网上搜索，并对其破解</p>
</li>
<li><p>插件安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. ConvertToUTF8 和 GBK Support</span><br><span class="line">2. Pretty Json</span><br><span class="line">3. SideBarEnhancements</span><br><span class="line">4. vim</span><br><span class="line">5. MarkdownPreview</span><br></pre></td></tr></table></figure>
</li>
<li><p>快捷键</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、使用Ctrl + `：打开或者关闭Sublime Text控制台。SublimeText控制台就是一个python的命令窗口。</span><br><span class="line">2、Ctrl+Shift+P：打开或者关闭命令行模式。</span><br><span class="line">3、Alt+Shift+2：分屏显示。( Alt+Shift+数字 )表示分几屏。默认即1，最大貌似是5。</span><br><span class="line">4、Sublime Text的一大亮点是支持多重选择——同时选择多个区域，然后同时进行编辑。Ctrl + D选择当前光标所在的词并高亮该词所有出现的位置，再次Ctrl + D选择该词出现的下一个位置。</span><br></pre></td></tr></table></figure></li>
</ol>

          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/23/mongo-spark-partitioner/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/23/mongo-spark-partitioner/" itemprop="url">mongo spark partitioner 详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-23T16:06:21+08:00">
                2018-09-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index">
                    <span itemprop="name">mysql</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  660
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><p><code>DefaultMongoPartitioner</code> 默认partitioner使用mongodb的抽样聚合操作( mongo版本需要大于3.2)，通过抽样来确定分区点, 对所有的mongo部署方式都可以</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">partitionKey 分区键</span><br><span class="line">partitionSizeMB 每个分区大小（没有太多实质性的意义,所以并不准）</span><br><span class="line">samplesPerPartition 每个分区抽样个数</span><br></pre></td></tr></table></figure>
<ul>
<li>第一步通过 <code>collStats</code> 聚合命令获取集合的统计信息</li>
<li>如果有 <code>match</code> 聚合操作就使用 <code>countDocuments(match)</code> 方法获取集合的数量</li>
<li>抽样获取集合分区键，并对集合进行分区</li>
</ul>
</li>
<li><p><code>MongoSplitVectorPartitioner</code>  通过 <code>SplitVector</code>命令来进行分区，需要 <code>ClusterManager</code> 权限， 这个命令的最初意图是对集合进行split，也就是对集群生成chunk分裂计划，所以mongo spark就借鉴这个命令进行分区划分， 主要对单节点或者复制集群使用</p>
<p>注意：适合 <code>match</code> 聚合中只使用 <code>$gt</code> 和 <code>$lt</code> 类型的比较符, 如果不是的那么它使用最小和最大键作为分区，这样分区之后由于它不会使用 <code>match</code> 所以可能导致分区并不是特别合适</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">partitionKey 分区键</span><br><span class="line">partitionSizeMB 每个分区大小（比较准确的值）</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>MongoShardedPartitioner</code> 直接对sharded集合进行分区，因为sharded集合本身就是分区的，所以mongo spark直接使用 <code>chunk</code> 大小作为分区大小，只能对shard集群使用，并且它还会给出 <code>chunk</code> 的具体位置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shardKey shard键</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>MongoPaginateByCountPartitioner</code> 通过分页数量来对分区，由于需要多次执行分页操作，而且越到大的分区其实是越慢的，所以没什么用，可以对任何部署方式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">partitionKey 分区键</span><br><span class="line">numberOfPartitions 每个分区数量</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>MongoPaginateBySizePartitioner</code> 通过分页集合大小来进行分区，和上面道理差不错多</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">partitionKey 分区键</span><br><span class="line">partitionSizeMB 每个分区大小</span><br></pre></td></tr></table></figure>
</li>
<li><p>从上面的集中分区方式可以，<code>DefaultMongoPartitioner</code> 之所以被当着默认的是因为它满足分和部署方式，并且性能一般也还可以。但是对于平时使用的过程中建议还是根据集群的部署方式以及 <code>match</code> 条件进行选择合适的 <code>partitioner</code> </p>
<ul>
<li>如果集群是单机或这复制集群，并且 <code>match</code> 中只有使用 <code>$gt</code> 和 <code>$lt</code> 类型的比较符， 那么推荐使用 <code>MongoSplitVectorPartitioner</code></li>
<li>如果是shard机器，那么直接使用 <code>MongoShardedPartitioner</code> ，并推荐看看 <code>chunk</code> 的具体位置怎么使用, 在现在mongo spark中并没有使用到这个参数</li>
<li>如果不是上面两种情况，那么直接使用使用 <code>DefaultMongoPartitioner</code> 就好了</li>
</ul>
</li>
</ol>

          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/05/hadoop-hbase-admin/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/05/hadoop-hbase-admin/" itemprop="url">hbase 常用管理命令</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-05T16:21:56+08:00">
                2018-08-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/hbase/" itemprop="url" rel="index">
                    <span itemprop="name">hbase</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,323
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="importtsv"><a href="#importtsv" class="headerlink" title="importtsv"></a>importtsv</h4><ul>
<li><p>命令参数说明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Usage: importtsv -Dimporttsv.columns=a,b,c [options] &lt;tablename&gt; &lt;inputdir&gt;</span><br><span class="line"></span><br><span class="line">importtsv.columns 导入的列常量</span><br><span class="line">HBASE_ROW_KEY 行健</span><br><span class="line">HBASE_TS_KEY 可选，put时使用的时间，指定这个列后 importtsv.timestamp 将会被忽略</span><br><span class="line">HBASE_CELL_TTL cell time to live</span><br><span class="line">HBASE_CELL_VISIBILITY visibility label expression.</span><br><span class="line">HBASE_ATTRIBUTES_KEY  key=&gt;value</span><br><span class="line"></span><br><span class="line">导入方式参数</span><br><span class="line">-Dimporttsv.bulk.output 使用bulkload方式导入，并指定bulkload的缓存位置</span><br><span class="line">其它参数</span><br><span class="line">-Dimporttsv.dry.run=true 测试模式，数据并非真正导入到表中，如果表不存在创建，并在最后删除</span><br><span class="line">-Dimporttsv.skip.bad.lines=false 是否跳过错误行</span><br><span class="line">-Dimporttsv.log.bad.lines=true log错误行</span><br><span class="line">-Dimporttsv.skip.empty.columns=false 是否跳过空的列</span><br><span class="line">&apos;-Dimporttsv.separator=|&apos; 使用管道代替tab分隔符</span><br><span class="line">-Dimporttsv.timestamp=currentTimeAsLong 使用当前时间</span><br><span class="line">-Dimporttsv.mapper.class=my.Mapper 自定义mapper代替org.apache.hadoop.hbase.mapreduce.TsvImporterMapper</span><br><span class="line">-Dmapreduce.job.name=jobName 指定job名字</span><br><span class="line">-Dcreate.table=no 避免创建表，导入的表必须存在hbase中</span><br><span class="line">-Dno.strict=false 是否严格模式，默认false忽略列族检查</span><br><span class="line">性能参数</span><br><span class="line">  -Dmapreduce.map.speculative=false</span><br><span class="line">  -Dmapreduce.reduce.speculative=false</span><br></pre></td></tr></table></figure>
</li>
<li><p>简单例子</p>
<ul>
<li><p>文件中的数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r0001	feng	29</span><br><span class="line">r0002	xiang	27</span><br></pre></td></tr></table></figure>
</li>
<li><p>直接导入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Driver importtsv -Dimporttsv.columns=HBASE_ROW_KEY,INFO:name,INFO:age user /user/hbase/user.tsv</span><br></pre></td></tr></table></figure>
</li>
<li><p>bulkload导入</p>
<ul>
<li><p>导出成HFiles</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Driver importtsv -Dimporttsv.columns=HBASE_ROW_KEY,INFO:name,INFO:age -Dimporttsv.bulk.output=/user/hbase/user_bulk user /user/hbase/user.tsv</span><br></pre></td></tr></table></figure>
</li>
<li><p>导入HFiles</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Driver completebulkload /user/hbase/user_bulk user</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="export"><a href="#export" class="headerlink" title="export"></a>export</h4><ul>
<li><p>命令参数说明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Usage: Export [-D &lt;property=value&gt;]* &lt;tablename&gt; &lt;outputdir&gt; [&lt;versions&gt; [&lt;starttime&gt; [&lt;endtime&gt;]] [^[regex pattern] or [Prefix] to filter]]</span><br><span class="line"></span><br><span class="line">扫描行存在两种过滤器，正则表达式和前缀</span><br><span class="line"></span><br><span class="line">输出SequenceFile的压缩形式</span><br><span class="line">   -D mapreduce.output.fileoutputformat.compress=true</span><br><span class="line">   -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec</span><br><span class="line">   -D mapreduce.output.fileoutputformat.compress.type=BLOCK</span><br><span class="line">指定Scan的参数</span><br><span class="line">   -D hbase.mapreduce.scan.column.family=&lt;family1&gt;,&lt;family2&gt;, ...</span><br><span class="line">   -D hbase.mapreduce.include.deleted.rows=true</span><br><span class="line">   -D hbase.mapreduce.scan.row.start=&lt;ROWSTART&gt;</span><br><span class="line">   -D hbase.mapreduce.scan.row.stop=&lt;ROWSTOP&gt;</span><br><span class="line">   -D hbase.client.scanner.caching=100</span><br><span class="line">   -D hbase.export.visibility.labels=&lt;labels&gt;，指定权限相关</span><br><span class="line">   -D hbase.export.scanner.batch=10</span><br><span class="line">   -D hbase.export.scanner.caching=100</span><br><span class="line">mapreduce参数</span><br><span class="line">   -D mapreduce.job.name=jobName</span><br><span class="line">   -D mapreduce.map.speculative=false</span><br><span class="line">   -D mapreduce.reduce.speculative=false</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong></p>
<ul>
<li>此处将versions和starttime endtime直接放入到命令行参数当中，可见通常情况下我们都是通过时间来进行增量拷贝</li>
<li>从这里就衍生出一个问题，我们真的需要将时间戳添加到rowkey当中吗？如果需要通过时间快速的查找那么通常情况下是需要的，如果仅仅只是备份那么通常情况下也不介意全表扫描。充分利用时间戳和版本信息。</li>
</ul>
</li>
<li><p>简单例子</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Driver export user /user/hbase/user_export</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="import"><a href="#import" class="headerlink" title="import"></a>import</h4><ul>
<li><p>命令参数说明</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Usage: Import [options] &lt;tablename&gt; &lt;inputdir&gt;</span><br><span class="line"></span><br><span class="line">导入方式参数</span><br><span class="line">  -Dimport.bulk.output=/path/for/output</span><br><span class="line">  -Dimport.bulk.hasLargeResult=true</span><br><span class="line">WAL参数</span><br><span class="line">  -Dimport.wal.durability=&lt;SKIP_WAL/ASYNC_WAL/SYNC_WAL/...&gt;</span><br><span class="line">使用Filter</span><br><span class="line">  -Dimport.filter.class=</span><br><span class="line">  -Dimport.filter.args=</span><br><span class="line">  -Dhbase.import.version=0.94 指定export导出的时hbase版本</span><br><span class="line">MapReduce参数</span><br><span class="line">  -D mapreduce.job.name=jobName</span><br><span class="line">  -Dmapreduce.map.speculative=false</span><br><span class="line">  -Dmapreduce.reduce.speculative=false</span><br></pre></td></tr></table></figure>
</li>
<li><p>简单例子</p>
<ul>
<li><p>直接导入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Driver import user /user/hbase/user_export</span><br></pre></td></tr></table></figure>
</li>
<li><p>bulkload导入</p>
<ul>
<li><p>导出成HFiles</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Driver import -Dimport.bulk.output=/user/hbase/user_import_bulk user /user/hbase/user_export</span><br></pre></td></tr></table></figure>
</li>
<li><p>导入HFiles</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Driver completebulkload /user/hbase/user_import_bulk user</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="sqoop-import"><a href="#sqoop-import" class="headerlink" title="sqoop import"></a>sqoop import</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --connect jdbc:mysql://cmsw1.tepia.com:3306/cmsw --username cmsw --password Cmsw@123 --table user --hbase-table user --column-family INFO --hbase-row-key id --hbase-bulkload</span><br></pre></td></tr></table></figure>
<h4 id="mapreduce-import"><a href="#mapreduce-import" class="headerlink" title="mapreduce import"></a>mapreduce import</h4><ul>
<li><p>编写MapReduce程序并打包成jar包</p>
</li>
<li><p>使用hadoop运行jar包，跟通用的MapReduce一样，但是需要指定hbase classpath</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_CLASSPATH=`$&#123;HBASE_HOME&#125;/bin/hbase classpath` $&#123;HADOOP_HOME&#125;/bin/hadoop jar user.jar</span><br></pre></td></tr></table></figure>
<p><strong>注意： </strong></p>
<ul>
<li>如果有classpath的问题，可以参照官网 <code>&lt;http://hbase.apache.org/book.html#hbase.mapreduce.classpath&gt;</code></li>
<li>如果MapReduce程序虚设置相关参数可以参照 <code>org.apache.hadoop.hbase.mapreduce.Driver</code> 中的基本类进行配置。</li>
</ul>
</li>
</ul>
<h4 id="copytable-import"><a href="#copytable-import" class="headerlink" title="copytable import"></a>copytable import</h4><ul>
<li><p>命令参数说明</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Usage: CopyTable [--options] [--starttime=X] [--endtime=Y] [--new.name=NEW] [--peer.adr=ADR] &lt;tablename&gt;</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line"> 控制参数</span><br><span class="line"> startrow     the start row</span><br><span class="line"> stoprow      the stop row</span><br><span class="line"> starttime    beginning of the time range (unixtime in millis)</span><br><span class="line">              without endtime means from starttime to forever</span><br><span class="line"> endtime      end of the time range.  Ignored if no starttime specified.</span><br><span class="line"> versions     number of cell versions to copy</span><br><span class="line"> families     comma-separated list of families to copy</span><br><span class="line">              To copy from cf1 to cf2, give sourceCfName:destCfName.</span><br><span class="line">              To keep the same name, just give "cfName"</span><br><span class="line"> all.cells    also copy delete markers and deleted cells</span><br><span class="line"> bulkload     Write input into HFiles and bulk load to the destination table</span><br><span class="line"> 目标集群信息</span><br><span class="line"> rs.class     hbase.regionserver.class of the peer cluster</span><br><span class="line">              specify if different from current cluster</span><br><span class="line"> rs.impl      hbase.regionserver.impl of the peer cluster</span><br><span class="line"> peer.adr    hbase.zookeeper.quorum:hbase.zookeeper.client.port:zookeeper.znode.parent</span><br><span class="line"> new.name     new table's name</span><br><span class="line"></span><br><span class="line">性能参数</span><br><span class="line">    -Dhbase.client.scanner.caching=100 通常应该&gt;=100</span><br><span class="line">    -Dmapreduce.map.speculative=false 永远为false</span><br><span class="line">    </span><br><span class="line">Examples:</span><br><span class="line"> To copy 'TestTable' to a cluster that uses replication for a 1 hour window:</span><br><span class="line"><span class="meta"> $</span> hbase org.apache.hadoop.hbase.mapreduce.CopyTable --starttime=1265875194289 --endtime=1265878794289 --peer.adr=server1,server2,server3:2181:/hbase --families=myOldCf:myNewCf,cf2,cf3 TestTable</span><br></pre></td></tr></table></figure>
</li>
<li><p>本地集群导入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase org.apache.hadoop.hbase.mapreduce.Driver copytable --families=INFO:info  --bulkload --new.name=user2 user</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="rowcounter"><a href="#rowcounter" class="headerlink" title="rowcounter"></a>rowcounter</h4><h4 id="CellCounter"><a href="#CellCounter" class="headerlink" title="CellCounter"></a>CellCounter</h4><h4 id="snapshot-export"><a href="#snapshot-export" class="headerlink" title="snapshot export"></a>snapshot export</h4><ul>
<li>在同一个集群中使用snapshot通常是用来数据的备份与恢复，并且它对整个hbase集群几乎没有影响</li>
<li>snapshot export工具是在两个集群中进行备份和恢复的</li>
</ul>

          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/01/hadoop-sqoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/01/hadoop-sqoop/" itemprop="url">sqoop使用教程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-01T14:07:24+08:00">
                2018-08-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/sqoop/" itemprop="url" rel="index">
                    <span itemprop="name">sqoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,990
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="前置设置"><a href="#前置设置" class="headerlink" title="前置设置"></a>前置设置</h4><ul>
<li><p>由于sqoop需要执行MapReduce任务，并且通常指定输出为 <code>/user/sqoop</code> 目录，所以需要创建并指定权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /user/sqoop</span><br><span class="line">hdfs dfs -chown sqoop:hdfs /user/sqoop</span><br></pre></td></tr></table></figure>
</li>
<li><p>建议使用需要访问目录的用户去执行sqoop命令</p>
</li>
<li><p>所有的sqoop import需要指定参数 <code>-Dorg.apache.sqoop.splitter.allow_text_splitter=true</code></p>
</li>
<li><p>每次执行MapReduce任务可能需要删除MapReduce任务输出目录</p>
</li>
<li><p>一般RDBMS的导出速度控制在60~80MB/s，每个 map 任务的处理速度5~10MB/s 估算，即 -m 参数一般设置4~8，表示启动 4~8 个map 任务并发抽取。</p>
</li>
<li><p>官网连接：<code>https://sqoop.apache.org/docs/1.4.7/SqoopUserGuide.html</code></p>
</li>
<li><p>hortonwork 教程： <code>https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.1.0/migrating-data/content/hive_moving_data_from_hdfs_to_hive.html</code></p>
</li>
<li><p>使用 <code>--skip-dist-cache</code> 防止每次需要将sqoop/lib中的jars上传到分布式缓存，所以如果sqoop/lib中的jars没有变化，那么每次都应该携带这个参数。</p>
</li>
<li><p>sqoop metastore 用来保存用户元数据信息，如使用sqoop job时候，创建job需要配置相关信息，并且需要保存last value。通常情况下每个用户一个metastore，通过文件的方式存储在 <code>~/.sqoop</code>目录当中。如果我们根据需要希望启动一个或者多个单独的metastore，那么只需要使用配置 <code>sqoop-site.xml</code> 并启动即可</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sqoop.metastore.server.location=/var/lib/sqoop/metastore.db</span><br><span class="line">sqoop.metastore.server.port=15999</span><br></pre></td></tr></table></figure>
<p>服务端启动</p>
<ul>
<li>创建 <code>/var/lib/sqoop</code> 和 <code>/var/log/sqoop</code> 文件夹，并分配权限</li>
<li>启动: <code>bin/start-metastore.sh -p /var/log/sqoop/metastore.pid -l /var/log/sqoop</code></li>
</ul>
<p>客户端使用</p>
<ul>
<li><p>方式一：通过命令行参数 <code>--meta-connect</code></p>
</li>
<li><p>方式二：在sqoop-site.xml中配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop.metastore.client.autoconnect.url=jdbc:hsqldb:hsql://metaserver:15999/sqoop</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="sqoop-import-参数说明"><a href="#sqoop-import-参数说明" class="headerlink" title="sqoop import 参数说明"></a>sqoop import 参数说明</h4><ul>
<li><p>MySQL连接参数</p>
<ul>
<li><code>--connect</code> 指定连接地址</li>
<li><code>--username, -P|--password|--password-file</code> 关系型数据库密码选项</li>
<li>注意sqoop是分布式方式运行，那么mysql连接需要在各个机器上都能够访问mysql服务器</li>
</ul>
</li>
<li><p>导入形式</p>
<ul>
<li><p>基本形式导入</p>
<ul>
<li><p>指定参数<code>--table --columns --where</code>  需要导出的表、列和条件</p>
</li>
<li><p>此处可以不用指定 <code>--target-dir</code> 是因为模式使用 <code>--table</code> 作为 MapReduce输出目录</p>
</li>
<li><p>示例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --connect jdbc:mysql://cmsw1.tepia.com:3306/cmsw --username cmsw --password Cmsw@123 --table r_cond_info</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>查询形式导入</p>
<ul>
<li><p>指定参数 <code>--query --split-by|-m 1 --target-dir</code> 查询语句、并行分区键（或者使用一个分区）和MapReduce输出目录</p>
</li>
<li><p><code>--split-limit</code>  限制分区最大值，防止MapReduce数据发送倾斜</p>
</li>
<li><p>示例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --connect jdbc:mysql://cmsw1.tepia.com:3306/cmsw --username cmsw --password Cmsw@123 --query &apos;select * from r_cond_info where $CONDITIONS&apos; --split-by stcd --target-dir &apos;/user/sqoop/r_cond_info_dir&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>说明</strong></p>
<ul>
<li>此处必须指定 <code>$CONDITIONS</code> ，并且它会在运行的时候进行替换成 <code>--split-by</code> 的条件</li>
<li>这种形式不能使用 <code>--as-orcfile</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>并行控制</p>
<ul>
<li>默认情况下使用 <code>select min(&lt;split-by&gt;), max(&lt;split-by&gt;) from &lt;table name&gt; where &lt;split-by&gt;</code>  来进行并行度控制，如果没有指定split-by则使用主键作为分区并行键，如果主键是分布不均匀的最好用split-by指定一个分区键，如果没有主键也没有指定分区键，那么默认情况下会报错，除非强制指定<code>--num-mappers 1</code> 或 <code>--autoreset-to-one-mapper</code> 使用单个mapper。</li>
<li>选择好分区键后，就是指定使用多少分区来运行，使用 <code>--num-mapers</code> 指定，如果存在数据倾斜的情况，可以指定 <code>--split-limit</code> 控制单个分区最大的量，从而影响并行度。</li>
<li><code>--autoreset-to-one-mapper</code> 通常用在import-all-tables工具中全库导入，没有主键使用单个mapper</li>
<li>基本形式和查询形式都可以进行并行度控制</li>
</ul>
</li>
<li><p>导入hive参数</p>
<ul>
<li><p><code>--hive-import --hive-database cmsw</code>  基本参数</p>
</li>
<li><p><code>--hive-table</code>  知道导入到hive中的表（修改默认mysql表名）</p>
</li>
<li><p><code>--create-hive-table</code> 如果hive中表存在，则报错</p>
</li>
<li><p><code>--hive-overwrite</code> 覆盖以及存在的表</p>
</li>
<li><p><code>--external-table-dir</code>  指定外部表的位置（这个外部表的位置就是MapReduce结果的位置, 注意运行sqoop的用户，因为此时hive需要访问MapReduce输出目录），这样hive表就是一个外部表，通常和 <code>--target-dir</code> 联合使用</p>
</li>
<li><p>示例</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --connect jdbc:mysql://cmsw1.tepia.com:3306/cmsw --username cmsw --password Cmsw@123 --table r_comm_info --hive-import --hive-database cmsw --as-orcfile</span><br></pre></td></tr></table></figure>
</li>
<li><p>sqoop直接迁移数据到hive当中，是先执行MapReduce任务将RDBMS中的数据按照指定的格式（如：–as-orcfile）写入到HDFS当中，再将HDFS中的数据复制到hive当中</p>
</li>
</ul>
</li>
<li><p>类型转换</p>
<ul>
<li><code>--map-column-java</code> 转换sql类型到java类型，如：<code>id=String,value=Integer</code></li>
<li><code>--map-column-hive</code> 转换sql类型到hive类型，转换的过程中需要转义，如：<code>DECIMAL(1%2C%201)</code> 代替 <code>DECIMAL(1, 1)</code></li>
</ul>
</li>
<li><p>导出类型控制</p>
<ul>
<li><code>--as-textfile</code> 默认为text类型</li>
<li><code>--as-avrodatafile</code>、<code>--as-orcfile</code>、<code>--as-parquetfile</code>、<code>--as-sequencefile</code></li>
<li>SequenceFile、text和Avro可以进行压缩，通过指定 <code>--compress</code> 或 <code>-z</code> 指定使用gzip进行压缩，或者指定 <code>--compression-codec</code> 设置hadoop的压缩格式</li>
</ul>
</li>
<li><p>text和sequence文件导出和导入格式（定界符），默认的定界符：字段 <code>,</code> ，行 <code>\n</code> ，无引号，无转码，这可能会导致字段或者行无法准确区分清楚，如某个String字段中存在逗号或者换行符，那么整个的定界就是错误的，所以为了明确的解析，必须指定定界符。</p>
<ul>
<li><p>字段含义</p>
<ul>
<li><code>--enclosed-by &lt;char&gt;</code> 必填字段包围符，如：通常会使用 <code>&#39;</code> 单引号或者 <code>&quot;</code> 双引号将字符串包围起来</li>
<li><code>--escaped-by &lt;char&gt;</code> 转义字符，如通常某些字符需要转义，转义字符通常是 <code>\</code></li>
<li><code>--fields-terminated-by</code> 在一行中，字段和字段之间的分隔符，如cvs文件中使用 <code>|</code> 或 <code>,</code></li>
<li><code>--lines-terminated-by</code> 行之间的分隔符，通常使用换行符 <code>\n</code> </li>
<li><code>--optionally-enclosed-by &lt;char&gt;</code> 可选字段包围符</li>
</ul>
</li>
<li><p>转义和包围符，如数据库中存在，如下数据</p>
<p>| String                       | int  | int  |<br>| —————————- | —- | —- |<br>| Some string, with a comma.   | 1    | 2    |<br>| Another “string with quotes” | 4    | 5    |</p>
<ul>
<li><p>明确定义符号 <code>sqoop import --fields-terminated-by , --escaped-by \\ --enclosed-by &#39;\&quot;&#39;</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;Some string, with a comma.&quot;,&quot;1&quot;,&quot;2&quot;</span><br><span class="line">&quot;Another \&quot;string with quotes\&quot;&quot;,&quot;4&quot;,&quot;5&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用可选包围符 <code>sqoop import --optionally-enclosed-by &#39;\&quot;&#39;</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;Some string, with a comma.&quot;,1,2</span><br><span class="line">&quot;Another \&quot;string with quotes\&quot;&quot;,4,5</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>hive默认是支持转义的，所以如果直接导入到hive当中，就不需要显示指定转义</p>
</li>
<li><code>--mysql-delimiters</code> 使用 <code>mysqldump</code> 默认的定界符，并使用direct模式，指定 <code>--direct</code> ，那么导入会非常快速，mysql默认的定界符 ，字段 <code>,</code> ，行 <code>\n</code> ， 转义 <code>\</code> ，可选包围符 <code>&#39;</code></li>
</ul>
</li>
</ul>
<h4 id="sqoop增量迁移数据到hive中"><a href="#sqoop增量迁移数据到hive中" class="headerlink" title="sqoop增量迁移数据到hive中"></a>sqoop增量迁移数据到hive中</h4><ul>
<li>增量导入，数据通常分为事实数据、可变维度数据、缓慢渐变维数据、快照表数据<ul>
<li>对于事实数据通常不会更改，只是简单递增，那么数据每次将最新的数据添加到已有的数据即可，使用append模式，通常append列为自增列</li>
<li>对于可变维度数据<ul>
<li>数据量比较小直接每次全量导出，不需要增量导出</li>
<li>如果数据量比较大，初始全量导出，以后每次增量导出新增和变化的数据即可，有两种合并方式<ul>
<li>方法一：直接使用 lastmodified + merge-key 合并新旧数据</li>
<li>方法而：直接使用hive的merge语句</li>
</ul>
</li>
</ul>
</li>
<li>缓慢渐变维度数据（如：数据T+1），首先初始化一次，后面每次导出T-1的数据，再将老的数据进行过期（更新的数据），再直接添加新的数据，所以只需要使用append模式即可，但append的列是时间列。</li>
</ul>
</li>
<li><p>sqoop增量迁移</p>
<ul>
<li><code>--incremental</code> 增量模式，append 和 lastmodified<ul>
<li>append 表示添加模式（单调递增主键不断添加数据），递增键可以是时间</li>
<li>lastmodified 最后修改模式 （存在一个单调递增值，修改数据后会自动增加，如表中存在最后修改时间字段），不支持hive，主要是hive默认是不支持更新。所以通常情况下先将数据进入hdfs当中，再创建hive external表进行管理。此模式通常需要合并原先的数据和新数据（新添加和修改的数据），所以通常需要指定 <code>--merge-key</code> 来合并新旧数据，如果在这个过程没有合并，那么也可以后面单独调用 <code>sqoop merge</code> 来进行合并操作。 </li>
</ul>
</li>
<li><code>--check-column</code> 指定检查的列，列不能为字符类型</li>
<li><code>--last-value</code> 指定最后增量值，或者最后修改的值</li>
</ul>
</li>
<li><p>MySQL中的表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `user` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `name` varchar(20) DEFAULT NULL,</span><br><span class="line">  `last_modify` datetime DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br></pre></td></tr></table></figure>
</li>
<li><p>hive中的表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> base_user(</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">int</span>, </span><br><span class="line">    <span class="keyword">name</span> <span class="keyword">string</span>, </span><br><span class="line">    last_modify <span class="keyword">string</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用基于查询的形式进行控制 lastmodified 类型</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --connect jdbc:mysql://cmsw1.tepia.com:3306/cmsw --username cmsw --password Cmsw@123 --query 'select * from user where last_modify &gt; "2019-01-01 00:00:00" and $CONDITIONS' --split-by id --target-dir '/user/hive/user' --hive-import --hive-database cmsw --hive-table increment_user --create-hive-table --external-table-dir '/user/hive/increment_user'</span><br></pre></td></tr></table></figure>
<p><strong>注意： </strong>每次执行前需要删除 <code>/user/hive/user</code> 、<code>/user/hive/increment_user</code> 以及hive表中的 <code>increment_user</code> 表</p>
</li>
<li><p>使用增量迁移参数进行控制 lastmodified 类型</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --connect jdbc:mysql://cmsw1.tepia.com:3306/cmsw --username cmsw --password Cmsw@123 --table user --target-dir '/user/hive/user' --incremental lastmodified --check-column last_modify --last-value '2019-01-01 00:00:00'</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong></p>
<ul>
<li>使用 <code>--incremental lastmodified</code> 不支持 hive import，只能后续多进行一个步骤</li>
<li>执行完成后需要记录 <code>--last-value</code> 的值供后面使用， 推荐使用sqoop job来执行</li>
</ul>
</li>
<li><p>最终将数据写入到基础hive表中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merge into base_user using increment_user on base_user.id = increment_user.id when matched then update set name=increment_user.name, last_modify=increment_user.last_modify when not matched then insert values(increment_user.id, increment_user.name, increment_user.last_modify);</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong></p>
<ul>
<li>使用merge语句建议为base表的连接字段添加主键索引，这样速度会明显加快</li>
</ul>
</li>
<li><p>使用基于查询的形式进行控制 append 类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --connect jdbc:mysql://cmsw1.tepia.com:3306/cmsw --username cmsw --password Cmsw@123 --query &apos;select * from user where id &gt; 0 and $CONDITIONS&apos; --split-by id --target-dir &apos;/user/hive/user&apos; --hive-import --hive-database cmsw --hive-table increment_user --create-hive-table --external-table-dir &apos;/user/hive/increment_user&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用增量迁移参数进行控制 append 类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --connect jdbc:mysql://cmsw1.tepia.com:3306/cmsw --username cmsw --password Cmsw@123 --table user --target-dir &apos;/user/hive/user&apos; --incremental append --check-column id --last-value 0 --hive-import --hive-database cmsw --hive-table increment_user --create-hive-table --external-table-dir &apos;/user/hive/increment_user&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>[选择] 如果已经创建hive外部表则不需要此步骤</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> increment_user (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">INT</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="keyword">STRING</span>,</span><br><span class="line">    last_modify <span class="keyword">STRING</span></span><br><span class="line">) <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span> <span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE location <span class="string">'/user/hive/user'</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>说明</p>
<ul>
<li><p>通常情况下对于事实性性的表都是需要根据时间进行分区的</p>
</li>
<li><p>对于维度表通常会进行修改和添加，这样lastmodified就是一个不错的选择了</p>
</li>
<li><p>当然最重要的还是hive支持的ACID和merge语句，这样能让我们更加容易维护整个表</p>
</li>
<li><p>对于只插入性质的表，通常可以创建一个 <code>insert-only transactional</code> 表，并且进行分区（不能直接使用删除语句，但是可以直接删除分区）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE T2(a int, b int) TBLPROPERTIES (&apos;transactional_properties&apos;=&apos;insert_only&apos;);</span><br></pre></td></tr></table></figure>
</li>
<li><p>不建议直接将数据从关系型数据库导入到hive中，使用hive中间表可以保证数据ACID</p>
</li>
<li><p>现在也可以直接使用hive的 <code>JdbcStorageHandler</code> 直接访问关系型数据库中的数据，这样更加简单</p>
</li>
</ul>
</li>
</ul>
<h4 id="导入案例"><a href="#导入案例" class="headerlink" title="导入案例"></a>导入案例</h4><ul>
<li><p>sqoop job 使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sqoop job --create default_sales_order \</span><br><span class="line">-- \</span><br><span class="line">import \</span><br><span class="line">--connect &quot;jdbc:mysql://hdp1.tepia.com:3306/source?useSSL=false&amp;user=feng&amp;password=feng@123&quot; \</span><br><span class="line">--table sales_order \</span><br><span class="line">--where &quot;entry_date &lt; current_date()&quot; \</span><br><span class="line">--hive-import \</span><br><span class="line">--hive-table default.sales_order \</span><br><span class="line">--incremental append \</span><br><span class="line">--check-column entry_date \</span><br><span class="line">--last-value &apos;1900-01-01&apos;</span><br></pre></td></tr></table></figure>
<p><strong>说明：</strong></p>
<ul>
<li>日期类型也可以作为一个自增字段</li>
<li>where添加后面控制，不会导入当前一天的数据，也就是说是通过一天为单位进行递增导入</li>
</ul>
</li>
<li><p>查看job信息，如 <code>last_value</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop job --show default_sales_order|grep last.value</span><br></pre></td></tr></table></figure>
</li>
</ul>

          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/01/hadoop-hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/01/hadoop-hive/" itemprop="url">hive集成其它系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-01T10:45:17+08:00">
                2018-08-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/hive/" itemprop="url" rel="index">
                    <span itemprop="name">hive</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,044
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="hive与其它系统集成说明"><a href="#hive与其它系统集成说明" class="headerlink" title="hive与其它系统集成说明"></a>hive与其它系统集成说明</h4><ul>
<li>现在hive使用StorageHandler只能创建external表, 外部表不能使用load语法</li>
<li>使用hive作为数据仓库，这样和其它系统直接集成，这样可以打通和其它系统直接的交互，直接导入导出数据</li>
<li>其它系统通过hive进行连接，也可以达到不同系统之间互通导数据</li>
</ul>
<h4 id="hive使用phoenix-PhoenixStorageHandler"><a href="#hive使用phoenix-PhoenixStorageHandler" class="headerlink" title="hive使用phoenix PhoenixStorageHandler"></a>hive使用phoenix PhoenixStorageHandler</h4><ul>
<li><p>配置hive访问phoenix jar包</p>
<ul>
<li><p>在hive-env.sh中配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_AUX_JARS_PATH=$&#123;HIVE_AUX_JARS_PATH&#125;:/usr/hdp/current/phoenix-client/phoenix-5.0.0.3.1.0.0-78-hive.jar</span><br></pre></td></tr></table></figure>
</li>
<li><p>在hive-site.xml中配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hive.aux.jars.path&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;/usr/hdp/current/phoenix-client/phoenix-5.0.0.3.1.0.0-78-hive.jar &lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>配置hive用户访问phoenix的系统表权限，通常使用ranger进行配置</p>
</li>
<li><p>在phoenix中创建测试表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table test(id integer not null primary key, name string, age integer);</span><br><span class="line">upsert into test values(1, &quot;xiang&quot;, 28);</span><br></pre></td></tr></table></figure>
</li>
<li><p>在hive中创建external表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">create external table test(id int, name string, age int)</span><br><span class="line">STORED BY &apos;org.apache.phoenix.hive.PhoenixStorageHandler&apos;</span><br><span class="line">TBLPROPERTIES (</span><br><span class="line">  &quot;phoenix.table.name&quot; = &quot;test&quot;,</span><br><span class="line">  &quot;phoenix.zookeeper.quorum&quot; = &quot;cmsw1.tepia.com,cmsw2.tepia.com,cmsw3.tepia.com&quot;,</span><br><span class="line">  &quot;phoenix.zookeeper.znode.parent&quot; = &quot;/hbase-unsecure&quot;,</span><br><span class="line">  &quot;phoenix.zookeeper.client.port&quot; = &quot;2181&quot;,  </span><br><span class="line">  &quot;phoenix.rowkeys&quot; = &quot;id&quot;,</span><br><span class="line">  &quot;phoenix.column.mapping&quot; = &quot;id:ID, name:NAME, age:AGE&quot;</span><br><span class="line">);</span><br><span class="line">insert into test values(2, &apos;feng&apos;, 30);</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置普通用户访问hive数据库的功能</p>
</li>
</ul>
<p><strong>说明：</strong></p>
<blockquote>
<p>将数据存储Phoenix，本质是HBase提供的SQL。用于后端的查询，要求RT在秒级以内。phoenix作为hbase二级索引的最佳组合，测试过上百万级别的数据构建二级索引最快的能在毫秒内返回。另外还有数据的统计分析及数据处理、机器学习建模，当然可以直接操作phoenix或spark+phoenix。对于离线的建模业务，我们希望使用hive做更复杂的处理。</p>
</blockquote>
<h4 id="hive使用HBaseStorageHandler"><a href="#hive使用HBaseStorageHandler" class="headerlink" title="hive使用HBaseStorageHandler"></a>hive使用HBaseStorageHandler</h4><ul>
<li><p>配置hive访问hbase jar包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">	&lt;name&gt;hive.aux.jars.path&lt;/name&gt;</span><br><span class="line">	&lt;value&gt;</span><br><span class="line">		/usr/hdp/3.1.0.0-78/hbase/lib/commons-lang3-3.6.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-zookeeper-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-mapreduce-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/jackson-annotations-2.9.5.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-shaded-miscellaneous-2.1.0.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/jackson-databind-2.9.5.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-hadoop-compat-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-metrics-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-client-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-protocol-shaded-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/jackson-core-2.9.5.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/protobuf-java-2.5.0.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-shaded-netty-2.1.0.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/metrics-core-3.2.1.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-server-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-hadoop2-compat-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-metrics-api-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-common-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-protocol-2.0.2.3.1.0.0-78.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/hbase-shaded-protobuf-2.1.0.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/htrace-core4-4.2.0-incubating.jar,</span><br><span class="line">        /usr/hdp/3.1.0.0-78/hbase/lib/zookeeper.jar</span><br><span class="line">	&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在创建hive时，需要添加访问hbase的权限，根据创建或者访问添加具体权限</p>
</li>
<li><p>hive可以设置hbase不需要写wal<code>set hive.hbase.wal.enabled=false</code></p>
</li>
<li><p>hbase表不存在，需要添加hbase的创建表权限（设置当前用户有创建hbase_table表的权限）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> hive_table (<span class="keyword">key</span> <span class="built_in">int</span>, <span class="keyword">value</span> <span class="keyword">string</span>) </span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span></span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (<span class="string">"hbase.columns.mapping"</span> = <span class="string">":key,cf1:val"</span>)</span><br><span class="line">TBLPROPERTIES (<span class="string">"hbase.table.name"</span> = <span class="string">"default:hbase_table"</span>);</span><br></pre></td></tr></table></figure>
<p><strong>说明： </strong></p>
<ul>
<li>hbase.columns.mapping 是必须的，这将会和 HBase 表的列族进行验证</li>
<li>hbase.table.name 属性是可选的，默认指定 HBase 表名与 Hive 表名一致</li>
<li>当将 hive_table 表删除，对应的 hbase_table 表不受影响，里面依旧有数据</li>
<li>当删除 hbase_table 表后，再查询 hive_table 表数据</li>
<li>hive外部表不支持load语句，所以可以直接将数据导入到hbase中，或者创建hive内部表使用load导入，再通过 <code>insert ... select ...</code> 语句导入到外部表中</li>
<li>Hive 读取的是 HBase 表最新的数据，并且创建的hbase表默认只有一个version, 可以修改最大version</li>
</ul>
</li>
<li><p>hbase存在，需要添加hbase访问权限</p>
<ul>
<li><p>hbase中创建表，并添加数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create &apos;person&apos;, &apos;cf&apos;</span><br><span class="line">put &apos;person&apos;, &apos;r001&apos;, &apos;cf:name&apos;, &apos;feng&apos;</span><br><span class="line">put &apos;person&apos;, &apos;r001&apos;, &apos;cf:age&apos;, &apos;10&apos;</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建hive表，并插入数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> person(<span class="keyword">id</span> <span class="keyword">string</span>, <span class="keyword">name</span> <span class="keyword">string</span>, age <span class="keyword">string</span>) <span class="keyword">stored</span> <span class="keyword">by</span> <span class="string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span> <span class="keyword">with</span> serdeproperties (<span class="string">"hbase.columns.mapping"</span> = <span class="string">":key,cf:name,cf:age"</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> person <span class="keyword">values</span>(<span class="string">'r002'</span>, <span class="string">'xiang'</span>, <span class="string">'12'</span>);</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="hive使用KafkaStorageHandler"><a href="#hive使用KafkaStorageHandler" class="headerlink" title="hive使用KafkaStorageHandler"></a>hive使用KafkaStorageHandler</h4><ul>
<li><p>创建默认json序列化表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> kafka_table(<span class="string">`message_type`</span> <span class="keyword">string</span>, <span class="string">`stcd`</span> <span class="keyword">string</span>, <span class="string">`tm`</span> <span class="keyword">string</span>) <span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">'org.apache.hadoop.hive.kafka.KafkaStorageHandler'</span> TBLPROPERTIES (<span class="string">"kafka.topic"</span> = <span class="string">"cmsw"</span>, <span class="string">"kafka.bootstrap.servers"</span>=<span class="string">"cmsw1.tepia.com:6667,cmsw2.tepia.com:6667,cmsw3.tepia.com:6667"</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>显示表的信息 <code>show create table kafka_table</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> <span class="string">`kafka_table`</span>(               </span><br><span class="line">  <span class="string">`message_type`</span> <span class="keyword">string</span> <span class="keyword">COMMENT</span> <span class="string">'from deserializer'</span>,  </span><br><span class="line">  <span class="string">`stcd`</span> <span class="keyword">string</span> <span class="keyword">COMMENT</span> <span class="string">'from deserializer'</span>,       </span><br><span class="line">  <span class="string">`tm`</span> <span class="keyword">string</span> <span class="keyword">COMMENT</span> <span class="string">'from deserializer'</span>,         </span><br><span class="line">  <span class="string">`__key`</span> <span class="built_in">binary</span> <span class="keyword">COMMENT</span> <span class="string">'from deserializer'</span>,      </span><br><span class="line">  <span class="string">`__partition`</span> <span class="built_in">int</span> <span class="keyword">COMMENT</span> <span class="string">'from deserializer'</span>,   </span><br><span class="line">  <span class="string">`__offset`</span> <span class="built_in">bigint</span> <span class="keyword">COMMENT</span> <span class="string">'from deserializer'</span>,   </span><br><span class="line">  <span class="string">`__timestamp`</span> <span class="built_in">bigint</span> <span class="keyword">COMMENT</span> <span class="string">'from deserializer'</span>) </span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> SERDE                                   </span><br><span class="line">  <span class="string">'org.apache.hadoop.hive.kafka.KafkaSerDe'</span>        </span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">BY</span>                                          </span><br><span class="line">  <span class="string">'org.apache.hadoop.hive.kafka.KafkaStorageHandler'</span>  </span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (                             </span><br><span class="line">  <span class="string">'serialization.format'</span>=<span class="string">'1'</span>)                      </span><br><span class="line">LOCATION    <span class="keyword">select</span> * <span class="keyword">from</span> (<span class="keyword">select</span> o.*, u.* <span class="keyword">from</span> ops_oder <span class="keyword">as</span> o <span class="keyword">join</span> dwd_dim_user <span class="keyword">as</span> u <span class="keyword">on</span> o.user_id = u.user_id) <span class="keyword">where</span> create_time &gt;= start_date <span class="keyword">and</span> create_time &lt;= end_date                                       </span><br><span class="line">  <span class="string">'hdfs://tepia/warehouse/tablespace/external/hive/kafka_table'</span> </span><br><span class="line">TBLPROPERTIES (                                    </span><br><span class="line">  <span class="string">'bucketing_version'</span>=<span class="string">'2'</span>,                         </span><br><span class="line">  <span class="string">'hive.kafka.max.retries'</span>=<span class="string">'6'</span>,                    </span><br><span class="line">  <span class="string">'hive.kafka.metadata.poll.timeout.ms'</span>=<span class="string">'30000'</span>,   </span><br><span class="line">  <span class="string">'hive.kafka.optimistic.commit'</span>=<span class="string">'false'</span>,          </span><br><span class="line">  <span class="string">'hive.kafka.poll.timeout.ms'</span>=<span class="string">'5000'</span>,             </span><br><span class="line">  <span class="string">'kafka.bootstrap.servers'</span>=<span class="string">'cmsw1.tepia.com:6667,cmsw2.tepia.com:6667,cmsw3.tepia.com:6667'</span>,  </span><br><span class="line">  <span class="string">'kafka.serde.class'</span>=<span class="string">'org.apache.hadoop.hive.serde2.JsonSerDe'</span>,  </span><br><span class="line">  <span class="string">'kafka.topic'</span>=<span class="string">'cmsw'</span>,                            </span><br><span class="line">  <span class="string">'kafka.write.semantic'</span>=<span class="string">'AT_LEAST_ONCE'</span>,          </span><br><span class="line">  <span class="string">'transient_lastDdlTime'</span>=<span class="string">'1565258896'</span>)</span><br></pre></td></tr></table></figure>
<p><strong>说明： </strong></p>
<ul>
<li>可以看到此处多了几个kafka记录元数据，并且每个元数据都可以用来作为条件过滤</li>
<li>kafka记录的值使用json、avro或者orc进行解码，解析后值的类型必须和hive指定的类型相匹配，不然会报错，通常情况下我们只需要映射需要的字段即可</li>
<li>此处 <code>kafka.write.semantic</code> 指定写入数据到kafka的语义，默认为最少一次，如果kafka版本支持事务，那么此处可以设置为 <code>&quot;kafka.write.semantic&quot;=&quot;EXACTLY_ONCE&quot;</code>精确一次</li>
<li>写入到kafka时，元数据列也必须设置，<code>__key</code> 设置出array以外的值，可以为null，<code>__partition</code>指定partition或者不设置，<code>__offset</code>固定为-1，<code>__timestamp</code> null或者-1（系统自动生产时间）或者有意义的时间（生产者可以指定的时间）</li>
</ul>
</li>
<li><p>示例</p>
<ul>
<li><p>查看最近十分钟数据记录</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> kafka_table </span><br><span class="line">  <span class="keyword">WHERE</span> <span class="string">`__timestamp`</span> &gt;  <span class="number">1000</span> * to_unix_timestamp(<span class="keyword">CURRENT_TIMESTAMP</span> - <span class="built_in">interval</span> <span class="string">'10'</span> MINUTES);</span><br></pre></td></tr></table></figure>
</li>
<li><p>与维度表进行连接</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//创建最近10分钟视图</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> last_10_minutes_of_kafka_table <span class="keyword">AS</span> <span class="keyword">SELECT</span>  <span class="string">`stcd`</span>, <span class="string">`message_type`</span>, <span class="string">`tm`</span> <span class="keyword">FROM</span> kafka_table </span><br><span class="line">  <span class="keyword">WHERE</span> <span class="string">`__timestamp`</span> &gt;  <span class="number">1000</span> * to_unix_timestamp(<span class="keyword">CURRENT_TIMESTAMP</span> - <span class="built_in">interval</span> <span class="string">'10'</span> MINUTES) ;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> stcd_table (<span class="string">`stcd`</span> <span class="keyword">string</span>, <span class="string">`name`</span> <span class="keyword">string</span> ,addr <span class="keyword">string</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> stcd, <span class="keyword">name</span>, <span class="keyword">sum</span>(message_type) <span class="keyword">from</span> last_10_minutes_of_kafka_table lk <span class="keyword">join</span> stcd_table st <span class="keyword">on</span> lk.stcd = st.stcd <span class="keyword">group</span> <span class="keyword">by</span> stcd, <span class="keyword">name</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">sum</span>(message_type)</span><br></pre></td></tr></table></figure>
</li>
<li><p>hive实现kafka ETL</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">//创建offset记录表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> kafka_table_offsets(partition_id <span class="built_in">int</span>, max_offset <span class="built_in">bigint</span>, insert_time <span class="keyword">timestamp</span>);                </span><br><span class="line">//初始化offset记录表</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> kafka_table_offsets </span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">`__partition`</span>, <span class="keyword">min</span>(<span class="string">`__offset`</span>) - <span class="number">1</span>, <span class="keyword">CURRENT_TIMESTAMP</span> </span><br><span class="line"><span class="keyword">FROM</span> kafka_table </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="string">`__partition`</span>, <span class="keyword">CURRENT_TIMESTAMP</span>;</span><br><span class="line">//创建ETL表</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> orc_kafka_table (partition_id <span class="built_in">int</span>, koffset <span class="built_in">bigint</span>, ktimestamp <span class="built_in">bigint</span>,</span><br><span class="line"><span class="string">`message_type`</span> <span class="keyword">string</span>, <span class="string">`stcd`</span> <span class="keyword">string</span>, <span class="string">`tm`</span> <span class="keyword">string</span>)</span><br><span class="line">//单事务中进行ETL</span><br><span class="line"><span class="keyword">FROM</span> kafka_table kt <span class="keyword">JOIN</span> kafka_table_offsets ot</span><br><span class="line"><span class="keyword">ON</span> (kt.<span class="string">`__partition`</span> = ot.partition_id </span><br><span class="line"><span class="keyword">AND</span> kt.<span class="string">`__offset`</span> &gt; ot.max_offset )</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> orc_kafka_table </span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">`__partition`</span>, <span class="string">`__offset`</span>, <span class="string">`__timestamp`</span>, message_type, stcd, tm</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> kafka_table_offsets </span><br><span class="line"><span class="keyword">SELECT</span> <span class="string">`__partition`</span>, <span class="keyword">max</span>(<span class="string">`__offset`</span>), <span class="keyword">CURRENT_TIMESTAMP</span> </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="string">`__partition`</span>, <span class="keyword">CURRENT_TIMESTAMP</span>;</span><br><span class="line">//重复上面步骤可以实现ETL，注意如果partition添加的时候需要更新offset表</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="hive使用JdbcStorageHandler"><a href="#hive使用JdbcStorageHandler" class="headerlink" title="hive使用JdbcStorageHandler"></a>hive使用JdbcStorageHandler</h4><ul>
<li><p>创建表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> user_jdbc(</span><br><span class="line">  <span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line">  <span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">  age <span class="built_in">int</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">'org.apache.hive.storage.jdbc.JdbcStorageHandler'</span></span><br><span class="line">TBLPROPERTIES (</span><br><span class="line">  <span class="string">"hive.sql.database.type"</span> = <span class="string">"MYSQL"</span>,</span><br><span class="line">  <span class="string">"hive.sql.jdbc.driver"</span> = <span class="string">"com.mysql.jdbc.Driver"</span>,</span><br><span class="line">  <span class="string">"hive.sql.jdbc.url"</span> = <span class="string">"jdbc:mysql://cmsw1.tepia.com/cmsw"</span>,</span><br><span class="line">  <span class="string">"hive.sql.dbcp.username"</span> = <span class="string">"cmsw"</span>,</span><br><span class="line">  <span class="string">"hive.sql.dbcp.password"</span> = <span class="string">"Cmsw@123"</span>,</span><br><span class="line">  <span class="string">"hive.sql.table"</span> = <span class="string">"user"</span>,</span><br><span class="line">  <span class="string">"hive.sql.dbcp.maxActive"</span> = <span class="string">"1"</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="Hive-与-ElasticSearch-的数据交互"><a href="#Hive-与-ElasticSearch-的数据交互" class="headerlink" title="Hive 与 ElasticSearch 的数据交互"></a>Hive 与 ElasticSearch 的数据交互</h4><h4 id="Hive-与-druid-的数据交互"><a href="#Hive-与-druid-的数据交互" class="headerlink" title="Hive 与 druid 的数据交互"></a>Hive 与 druid 的数据交互</h4>
          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/01/hadoop-phoenix/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/01/hadoop-phoenix/" itemprop="url">phoenix使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-01T10:45:13+08:00">
                2018-08-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">hadoop</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/phoenix/" itemprop="url" rel="index">
                    <span itemprop="name">phoenix</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,215
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="phoenix-读写考虑"><a href="#phoenix-读写考虑" class="headerlink" title="phoenix 读写考虑"></a>phoenix 读写考虑</h4><ul>
<li><p>phoenix 不可变表，可以进行更新，但是是整体的一行进行替换，如果创建不可变表的索引那么在更新数据之后，会导致索引表中存在脏数据（以往索引的数据），这是因为索引是通过row key进行创建的，无法自动删除，所以对于不可变表最好就是不要进行更新。</p>
</li>
<li><p>phoenix 在每一行中添加一个默认的列，并且设置为 <code>x</code>，每次更新都会自动更新这一列</p>
</li>
<li><p>性能影响最大的因素一定是主键、salt 表(<code>http://phoenix.apache.org/salted.html</code>)以及schema设计</p>
</li>
<li><p>关注读性能，通常是创建多个global index, <code>http://phoenix.apache.org/secondary_indexing.html</code></p>
</li>
<li><p>关注写性能，预定义分区或使用salt表，使用真实类型代替原始类型，使用local index</p>
</li>
<li><p>为了保证读性能，可以考虑使用覆盖索引， <code>CREATE INDEX index ON table（...）INCLUDE(...)</code></p>
</li>
<li><p>可选设置 <code>IMMUTABLE_ROWS=true</code></p>
</li>
<li><p>如果速度更加重要，设置 <code>DISABLE_WAL</code>， 注意可能会丢失数据</p>
</li>
<li><p><code>row timestamp</code> 将hbase行的时间映射到行键上面，这样在scan的时候就可以使用这个时间了，这个时间可以自己设置，也可以让hbase服务端自动设置, 一旦这个时间写入到行键，那么行健肯定是不会变了。但是如果行进行了update，那么此时默认列 <code>x</code> 的时间戳会更新, 可见每次进行更新的时候，系统都会带上默认列进行更新。从上面的信息可以看出，<code>row_timestamp</code> 仅仅只是提供了一种可以不用设置时间的方式并显示它， 但是在实际使用过程中并没有任何用处，所以如果没有特别的理由，最好不要使用这个时间戳，说明 <code>http://phoenix.apache.org/rowtimestamp.html</code></p>
</li>
<li><p>如果表的元数据改变不是特别平凡，设置 <code>UPDATE_CACHE_FREQUENCY</code>为15分钟左右</p>
</li>
<li><p>如果数据表不是稀疏表（超过50%列有值），设置 <code>SINGLE_CELL_ARRAY_WITH_OFFSETS</code> 数据编码模式（将整个列族的一行放入到一个hbase cell当中）, <code>http://phoenix.apache.org/columnencoding.html</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> IMMUTABLE <span class="keyword">TABLE</span> T   </span><br><span class="line">(  </span><br><span class="line">    a_string <span class="built_in">varchar</span> <span class="keyword">not</span> <span class="literal">null</span>,   </span><br><span class="line">    col1 <span class="built_in">integer</span>  </span><br><span class="line">    <span class="keyword">CONSTRAINT</span> pk PRIMARY <span class="keyword">KEY</span> (a_string)  </span><br><span class="line">)   </span><br><span class="line">IMMUTABLE_STORAGE_SCHEME = SINGLE_CELL_ARRAY_WITH_OFFSETS,  </span><br><span class="line">COLUMN_ENCODED_BYTES = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置块编码 <code>CREATE TABLE … ( … ) DATA_BLOCK_ENCODING=‘FAST_DIFF’</code> ， <code>FAST_DIFF</code> 和 <code>SNAPPY</code> 都是不错的选择</p>
</li>
<li><p>表的数据如果存在分离，创建多个列族</p>
</li>
<li><p>对于结构体对象，不要使用json（压缩性能不好），可以使用protobuf、avro、bson等等</p>
</li>
<li><p>尽量不要关闭列mapping</p>
</li>
<li><p>表太大使用 <code>ASYNC</code> 创建index， <code>if not exists event_object_id_idx_b on trans.event (object_id) ASYNC UPDATE_CACHE_FREQUENCY=60000</code></p>
</li>
<li><p>大范围查询，可以使用 <code>GZIP</code> 压缩，但是需要注意写性能，以及在scan的时候，设置 <code>Scan.setCacheBlocks(false)</code></p>
</li>
<li><p>对于大的查询或者连接查询，推荐使用 <code>Hints</code> 来优化性能</p>
</li>
<li><p>对于大客户端，不要使用 <code>executeBatch</code> ，使用多条进行<code>update and commit</code>，对于瘦客户端，推荐使用 <code>executeBatch</code>，可以减少与query server的RPC调用</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">try (Connection conn = DriverManager.getConnection(url)) &#123;</span><br><span class="line">  conn.setAutoCommit(false);</span><br><span class="line">  int batchSize = 0;</span><br><span class="line">  int commitSize = 1000; // number of rows you want to <span class="keyword">commit</span> per batch.  </span><br><span class="line">  try (<span class="keyword">Statement</span> stmt = conn.prepareStatement(<span class="keyword">upsert</span>)) &#123;</span><br><span class="line">    stmt.set ... <span class="keyword">while</span> (there <span class="keyword">are</span> <span class="keyword">records</span> <span class="keyword">to</span> <span class="keyword">upsert</span>) &#123;</span><br><span class="line">      stmt.executeUpdate(); </span><br><span class="line">      batchSize++; </span><br><span class="line">      if (batchSize % commitSize == 0) &#123; </span><br><span class="line">        conn.commit(); </span><br><span class="line">      &#125; </span><br><span class="line">   &#125; </span><br><span class="line"> conn.commit(); // <span class="keyword">commit</span> the <span class="keyword">last</span> batch <span class="keyword">of</span> <span class="keyword">records</span> </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>update ... select ...</code> 插入大量数据时候，通常打开 <code>autocommit</code> 并且设置 <code>phoenix.mutate.batchSize</code></p>
</li>
<li><p>删除大量数据时候，通常打开 <code>autoCommit</code>，这样region server直接删除，而不需要返回row key到客户端</p>
</li>
<li><p>对于应用来说，快速失败比让客户端等待要好得多，可以设置更改等待时间<code>phoenix.query.timeoutMs</code>，配置设置参考 <code>http://phoenix.apache.org/tuning.html</code></p>
</li>
</ul>
<h4 id="CsvBulkLoadTool"><a href="#CsvBulkLoadTool" class="headerlink" title="CsvBulkLoadTool"></a>CsvBulkLoadTool</h4><ul>
<li><p>参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">-a,--array-delimiter &lt;arg&gt;   数组元素分隔符，默认冒号</span><br><span class="line">-b,--binaryEncoding &lt;arg&gt;    Specifies binary encoding</span><br><span class="line">-c,--import-columns &lt;arg&gt;    导入的列，逗号分割</span><br><span class="line">-d,--delimiter &lt;arg&gt;         字段分隔符，默认逗号</span><br><span class="line">-e,--escape &lt;arg&gt;            转移字符，默认反斜线</span><br><span class="line">-g,--ignore-errors           Ignore input errors</span><br><span class="line">-h,--help                    Show this help and quit</span><br><span class="line">-i,--input &lt;arg&gt;             输入路径，逗号分割</span><br><span class="line">-it,--index-table &lt;arg&gt;      当导入索引时，指定索引表</span><br><span class="line">-o,--output &lt;arg&gt;            输出临时HFile路径</span><br><span class="line">-q,--quote &lt;arg&gt;             自定义短语分隔符，默认双引号</span><br><span class="line">-s,--schema &lt;arg&gt;            Phoenix schema name (optional)</span><br><span class="line">-t,--table &lt;arg&gt;             Phoenix table name (mandatory)</span><br><span class="line">-z,--zookeeper &lt;arg&gt;         zookeeper连接信息</span><br></pre></td></tr></table></figure>
</li>
<li><p>基本命令形式</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u hbase HADOOP_CLASSPATH=$(hbase mapredcp):/usr/hdp/current/hbase-client/conf hadoop jar /usr/hdp/current/phoenix-client/phoenix-5.0.0.3.1.0.0-78-client.jar org.apache.phoenix.mapreduce.CsvBulkLoadTool</span><br></pre></td></tr></table></figure>
</li>
<li><p>字段分隔符设置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-d $‘\t’</span><br></pre></td></tr></table></figure>
</li>
<li><p>小写表名转义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--table \&quot;\&quot;t\&quot;\&quot;</span><br></pre></td></tr></table></figure>
</li>
<li><p>注意，还有一个工具可以完成表导入工具 <code>psql.py</code>, 并且它是使用单线程phoenix客户端的方式，每秒2-5万条数据</p>
<ul>
<li>首先使用 <code>psql.py create_table.sql</code></li>
<li>再使用 <code>psql.py load_data.cvs</code></li>
</ul>
</li>
</ul>
<h4 id="JsonBulkLoadTool"><a href="#JsonBulkLoadTool" class="headerlink" title="JsonBulkLoadTool"></a>JsonBulkLoadTool</h4><h4 id="IndexToolUtil"><a href="#IndexToolUtil" class="headerlink" title="IndexToolUtil"></a>IndexToolUtil</h4><h4 id="IndexScrutinyTool"><a href="#IndexScrutinyTool" class="headerlink" title="IndexScrutinyTool"></a>IndexScrutinyTool</h4><h4 id="映射hbase表到phoenix"><a href="#映射hbase表到phoenix" class="headerlink" title="映射hbase表到phoenix"></a>映射hbase表到phoenix</h4>
          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/19/kafka-shell-command/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ilivoo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/my-icon.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ilivoo`s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/19/kafka-shell-command/" itemprop="url">kafka 命令行工具</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-19T09:21:58+08:00">
                2018-07-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/kafka/" itemprop="url" rel="index">
                    <span itemprop="name">kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,321
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="kafka使用kerberos"><a href="#kafka使用kerberos" class="headerlink" title="kafka使用kerberos"></a>kafka使用kerberos</h4><p>连接zookeeper一定要带上zookeeper上kafka的节点，如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/hdp/3.0.1.0-187/kafka/bin/kafka-topics.sh --list --zookeeper cmsw1.tepia.com:2181/kafka</span><br></pre></td></tr></table></figure>
<h4 id="kafka-console-producer-sh"><a href="#kafka-console-producer-sh" class="headerlink" title="kafka-console-producer.sh"></a>kafka-console-producer.sh</h4><p>用来往topic中生产消息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list hadoop3.feng.com:9092 --property &quot;parse.key=true&quot; --property &quot;key.separator=:&quot; --topic kafka</span><br></pre></td></tr></table></figure></p>
<h5 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h5><ol>
<li>–broker-list –topic 指定broker列表和生产消息的topic</li>
<li>–property 指定console读取消息的kafka.tools.ConsoleProducer$LineMessageReader的属性， 也可以–line-reader指定默认的行读取器， 可以指定三个参数：<ol>
<li>parse.key true 表示是否解析key， 如果不解析默认key为null</li>
<li>key.separator 指定key分隔符， 默认为 \t</li>
<li>ignore.error true 指定是否忽略错误</li>
</ol>
</li>
<li>如果不解析key那么， 生产的消息会均匀的发送到所有的Partition当中</li>
<li>–producer.config –producer-property 通过配置文件或者直接指定key=value去指定生产者的属性，用于在设置命令行中没有提供的参数</li>
<li>–key-serializer –value-serializer –compression-codec 指定key value的序列化和压缩方式</li>
</ol>
<h4 id="kafka-console-consumer-sh"><a href="#kafka-console-consumer-sh" class="headerlink" title="kafka-console-consumer.sh"></a>kafka-console-consumer.sh</h4><p>用来消费topic中的消息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server hadoop2.feng.com:9092 --topic kafka --property print.key=true --property &quot;key.separator=:&quot; --from-beginning</span><br></pre></td></tr></table></figure></p>
<h5 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h5><ol>
<li>–broker-list –topic 指定broker列表和消费的topic</li>
<li>–property 指定console读取消息的kafka.tools.DefaultMessageFormatter的属性， 也可以–formatter指定默认的行读取器， 可以指定三个参数：<ol>
<li>print.key true 打印key</li>
<li>print.value true 打印value</li>
<li>key.separator 指定key分隔符</li>
<li>line.separator 指定行分隔符</li>
</ol>
</li>
<li>–from-beginning 指定从日志头开始消费</li>
<li>–group 指定消费者组， 如果不指定那么默认会自动生产一个唯一的消费者组， 如果想要多个不同的consumer消费某个topic那么此处必须指定</li>
<li>–Partition 指定消费的topic的分组， 如果不指定默认消费全部的分组</li>
<li>–offset 指定消费者的位置非负整数或者earliest和latest， 默认为latest</li>
<li>–consumer.config –consumer-property 通过配置文件或者直接指定key=value去指定消费者的属性，用于在设置命令行中没有提供的参数</li>
<li>–isolation-level read_uncommitted/read_committed 指定隔离级别， 用于支持读取消息的一致性语义</li>
</ol>
<h4 id="kafka-consumer-groups-sh"><a href="#kafka-consumer-groups-sh" class="headerlink" title="kafka-consumer-groups.sh"></a>kafka-consumer-groups.sh</h4><p>用来管理消费者组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-consumer-groups.sh --bootstrap-server hadoop1.feng.com:9092 --group console-consumer-38042 --describe</span><br></pre></td></tr></table></figure></p>
<h5 id="说明-2"><a href="#说明-2" class="headerlink" title="说明"></a>说明</h5><ol>
<li>此命令主要存在四个功能–list, –describe, –delete, –reset-offsets</li>
<li>–list 显示所有的消费者组</li>
<li>–describe 显示某个消费者组的详细信息</li>
<li>–delete 删除某个消费者组</li>
<li>–reset-offsets 重新设置消费者组的偏移量 </li>
</ol>
<h4 id="kafka-log-dirs-sh"><a href="#kafka-log-dirs-sh" class="headerlink" title="kafka-log-dirs.sh"></a>kafka-log-dirs.sh</h4><p>用来查看broker的日志保存信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-log-dirs.sh --bootstrap-server hadoop1.feng.com:9092 --describe --topic-list kafka --broker-list 2</span><br></pre></td></tr></table></figure></p>
<h5 id="说明-3"><a href="#说明-3" class="headerlink" title="说明"></a>说明</h5><ol>
<li>–topic-list 需要显示的topic</li>
<li>–broker-list 需要显示的brokers</li>
</ol>
<h4 id="kafka-delete-records-sh"><a href="#kafka-delete-records-sh" class="headerlink" title="kafka-delete-records.sh"></a>kafka-delete-records.sh</h4><p>用来删除记录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-delete-records.sh --bootstrap-server hadoop1.feng.com:9092 --offset-json-file myconfig/kafka-delete-records.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    &quot;partitions&quot;:</span><br><span class="line">        [</span><br><span class="line">            &#123;&quot;topic&quot;: &quot;kafka&quot;, &quot;partition&quot;: 0,&quot;offset&quot;: 20&#125;</span><br><span class="line">        ],</span><br><span class="line">    &quot;version&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h5 id="说明-4"><a href="#说明-4" class="headerlink" title="说明"></a>说明</h5><ol>
<li>对于kafka来说默认存在两种删除策略， 一种基于日志量， 二种基于日志保存的时间， 但是有时候我们需要手动的去指定删除到具体的位置， 这个脚本就比较有用了</li>
<li>日志可能未必立即删除， 但是以及无法消费删除的日志了</li>
</ol>
<h4 id="kafka-preferred-replica-election-sh"><a href="#kafka-preferred-replica-election-sh" class="headerlink" title="kafka-preferred-replica-election.sh"></a>kafka-preferred-replica-election.sh</h4><p>用来对某个topic的分区进行选举prefered replica， 分区的leader用来读写的， 从而平衡kafka集群<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-preferred-replica-election.sh --zookeeper hadoop1.feng.com:2181 --path-to-json-file myconfig/kafka-preferred-replica-election.json</span><br></pre></td></tr></table></figure></p>
<h5 id="说明-5"><a href="#说明-5" class="headerlink" title="说明"></a>说明</h5><ol>
<li>此处的选举主要是为了kafka能够平衡负载， 并且kafka也保留了auto.leader.rebalance.enable来自动进行分区leader选举， 造成不平衡的原理是因为broker添加或者是broker失败恢复</li>
</ol>
<h4 id="kafka-reassign-partitions-sh"><a href="#kafka-reassign-partitions-sh" class="headerlink" title="kafka-reassign-partitions.sh"></a>kafka-reassign-partitions.sh</h4><p>生产分配方案<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-reassign-partitions.sh --zookeeper hadoop1.feng.com:2181 --generate --topics-to-move-json-file myconfig/kafka-reassign-partitions-generate.json --broker-list 0,1,2</span><br><span class="line"></span><br><span class="line">Current partition replica assignment</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[]&#125;</span><br><span class="line"></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[]&#125;</span><br><span class="line"></span><br><span class="line">kafka-reassign-partitions-generate.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;topics&quot;:</span><br><span class="line">        [</span><br><span class="line">            &#123;&quot;topic&quot;: &quot;kafka&quot;&#125;</span><br><span class="line">        ],</span><br><span class="line">    &quot;version&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h5 id="说明-6"><a href="#说明-6" class="headerlink" title="说明"></a>说明</h5><ol>
<li>–generate 生成重新分区方案， –topic-to-move-json-file指定需要移动的topic信息， –broker-list 指定移动到的broker</li>
<li>此处打印出当前的分配信息， 以及建议的分配信息， 可以讲建议信息作为–reassignment-json-file的参数进行手动的执行</li>
<li>这里不需要指定bootstrap-server是因为当重新进行分配分区的时候实际上仅仅只是在zookeeper中更改状态， 当controller获取到状态的时候就异步的去执行当前分配策略</li>
</ol>
<p>执行分配<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-reassign-partitions.sh --zookeeper hadoop1.feng.com:2181 --execute --reassignment-json-file myconfig/kafka-reassign-partitions-execute.json</span><br><span class="line"></span><br><span class="line">&#123;&quot;version&quot;:1,&quot;partitions&quot;:[]&#125;</span><br></pre></td></tr></table></figure></p>
<ol>
<li>在Partition移动的过程中会有大量的io操作， 所以对于集群中网络带宽这种稀有资源应该加以限制， 使用throttle进行设定</li>
</ol>
<p>检查分配<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-reassign-partitions.sh --zookeeper hadoop1.feng.com:2181 --verify --reassignment-json-file myconfig/kafka-reassign-partitions-execute.json</span><br></pre></td></tr></table></figure></p>
<ol>
<li>检查移动分区的执行情况</li>
<li>移除当前移动分区时设置的网络配额</li>
</ol>

          
        
      
    </div>
    <div>
        
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/my-icon.jpeg"
                alt="ilivoo" />
            
              <p class="site-author-name" itemprop="name">ilivoo</p>
              <p class="site-description motion-element" itemprop="description">我，在這裡，享受等你的時光。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">56</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ilivoo</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

  <script type="text/javascript" src="/lib/clipboard/clipboard.js"></script>
<script type="text/javascript" src="/js/src/custom.js"></script>

</body>
</html>
